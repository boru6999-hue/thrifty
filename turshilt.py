import cv2
import numpy as np
import pytesseract
from datetime import datetime, timedelta
import os
from collections import deque
import tkinter as tk
from tkinter import filedialog

# Tesseract –∑–∞–º
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'


class FastPlateDetector:
    def __init__(self):
        self.save_folder = "detected_plates"
        if not os.path.exists(self.save_folder):
            os.makedirs(self.save_folder)

        self.cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_russian_plate_number.xml'
        )

        self.detected_plates = []

        # –î–ê–í–•–¶–ê–õ —à–∞–ª–≥–∞—Ö - —Å–∞–π–∂—Ä—É—É–ª—Å–∞–Ω
        self.seen_plates = {}  # {plate_text: {'frame': int, 'time': float, 'count': int}}

        # –®–∞–ª–≥—É—É—Ä
        self.MIN_CONFIDENCE = 65
        self.MIN_SAME_FRAME_GAP = 60  # 60 frame (2 —Å–µ–∫—É–Ω–¥ @ 30fps)
        self.MIN_SAME_TIME_GAP = 3.0   # 3 —Å–µ–∫—É–Ω–¥

        print("‚úÖ –•—É—Ä–¥–∞–Ω —Å–∏—Å—Ç–µ–º –±—ç–ª—ç–Ω!")

    def select_video(self):
        root = tk.Tk()
        root.withdraw()
        video_path = filedialog.askopenfilename(
            title="–í–∏–¥–µ–æ —Å–æ–Ω–≥–æ—Ö",
            filetypes=[
                ("Video files", "*.mp4 *.avi *.mov *.mkv *.flv *.wmv"),
                ("All files", "*.*")
            ]
        )
        root.destroy()
        return video_path

    def format_video_time(self, seconds):
        """–°–µ–∫—É–Ω–¥ ‚Üí MM:SS —Ñ–æ—Ä–º–∞—Ç"""
        mins = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{mins:02d}:{secs:02d}"

    def is_valid_plate(self, text):
        """–î—É–≥–∞–∞—Ä—ã–Ω —Ñ–æ—Ä–º–∞—Ç - –•–ê–¢–£–£ —à–∞–ª–≥–∞—Ö"""
        if not text or len(text) < 5 or len(text) > 10:
            return False

        # –ó”©–≤—Ö”©–Ω “Ø—Å—ç–≥ —Ç–æ–æ
        if not text.isalnum():
            return False

        # –ó–ê–ê–í–ê–õ –¥–æ—Ä —Ö–∞—è–∂ 2 —Ç–æ–æ –±–∞–π—Ö —ë—Å—Ç–æ–π
        digit_count = sum(c.isdigit() for c in text)
        if digit_count < 2:
            return False

        # –ó–ê–ê–í–ê–õ –¥–æ—Ä —Ö–∞—è–∂ 1 “Ø—Å—ç–≥ –±–∞–π—Ö —ë—Å—Ç–æ–π
        letter_count = sum(c.isalpha() for c in text)
        if letter_count < 1:
            return False

        # –ë—É—Ä—É—É pattern –∞–ª–≥–∞—Å–∞—Ö
        # –•—ç—Ä—ç–≤ –∑”©–≤—Ö”©–Ω “Ø—Å—ç–≥ —ç—Å–≤—ç–ª –∑”©–≤—Ö”©–Ω —Ç–æ–æ –±–æ–ª –±—É—Ä—É—É
        if digit_count == 0 or letter_count == 0:
            return False

        return True

    def is_duplicate(self, text, frame_number, video_time):
        """–ò–õ“Æ“Æ —Å–∞–π–Ω –¥–∞–≤—Ö—Ü–∞–ª —à–∞–ª–≥–∞—Ö"""
        if text not in self.seen_plates:
            # –®–∏–Ω—ç –¥—É–≥–∞–∞—Ä
            self.seen_plates[text] = {
                'frame': frame_number,
                'time': video_time,
                'count': 1
            }
            return False

        # –•—É—É—á–∏–Ω –¥—É–≥–∞–∞—Ä - —à–∞–ª–≥–∞—Ö
        last_seen = self.seen_plates[text]
        frame_gap = frame_number - last_seen['frame']
        time_gap = video_time - last_seen['time']

        # –•—ç—Ä—ç–≤ —Ö–∞–Ω–≥–∞–ª—Ç—Ç–∞–π –∑–∞–π –±–∞–π–≤–∞–ª —à–∏–Ω—ç –≥—ç–∂ —Ç–æ–æ—Ü–æ—Ö
        if frame_gap >= self.MIN_SAME_FRAME_GAP and time_gap >= self.MIN_SAME_TIME_GAP:
            # –ó–∞—Å–≤–∞—Ä–ª–∞—Ö - —à–∏–Ω—ç –¥—É–≥–∞–∞—Ä –±–∏—à, –∑”©–≤—Ö”©–Ω –º—ç–¥—ç—ç–ª—ç–ª —à–∏–Ω—ç—á–ª—ç—Ö
            self.seen_plates[text]['frame'] = frame_number
            self.seen_plates[text]['time'] = video_time
            self.seen_plates[text]['count'] += 1
            return False  # –î–∞—Ö–∏–Ω —Ö–∞—Ä—É—É–ª–∞—Ö—ã–≥ –∑”©–≤—à”©”©—Ä”©—Ö

        # –•—ç—Ç –æ–π—Ä—Ö–æ–Ω –±–æ–ª –¥–∞–≤—Ö—Ü—Å–∞–Ω –≥—ç–∂ “Ø–∑—ç—Ö
        return True

    def detect_plates(self, frame):
        """–•–£–†–î–ê–ù –∏–ª—Ä“Ø“Ø–ª—ç—Ö"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        plates = self.cascade.detectMultiScale(
            gray,
            scaleFactor=1.15,  # –¢–æ–º scale = –∏–ª“Ø“Ø —Ö—É—Ä–¥–∞–Ω
            minNeighbors=3,
            minSize=(70, 25)
        )

        # –•–∞—Ä—å—Ü–∞–∞ —à–∞–ª–≥–∞—Ö
        valid = []
        for (x, y, w, h) in plates:
            ratio = w / h
            if 2.0 <= ratio <= 5.5:
                valid.append((x, y, w, h))

        return valid

    def enhance_plate_fast(self, plate_img):
        """–ú–ê–ê–®–ì“Æ–ô –•–£–†–î–ê–ù –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞–ª—Ç"""
        if len(plate_img.shape) == 3:
            gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)
        else:
            gray = plate_img.copy()

        h, w = gray.shape

        # –¢–æ–º –±–æ–ª–≥–æ—Ö - –∑–æ—Ö–∏–º–∂—Ç–æ–π —Ö—ç–º–∂—ç—ç
        target_h = 120
        scale = target_h / h
        gray = cv2.resize(gray, (int(w * scale), target_h),
                          interpolation=cv2.INTER_CUBIC)

        # –≠–Ω–≥–∏–π–Ω denoise
        gray = cv2.GaussianBlur(gray, (3, 3), 0)

        # CLAHE
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        gray = clahe.apply(gray)

        # Threshold - OTSU —Ö–∞–º–≥–∏–π–Ω —Ö—É—Ä–¥–∞–Ω
        _, binary = cv2.threshold(
            gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

        return binary

    def ocr_improved(self, img):
        """OCR - —Å–∞–π–∂—Ä—É—É–ª—Å–∞–Ω –±—É—Ä—É—É —Ç–∞–Ω–∏–ª—Ç—ã–≥ –∑–∞—Å–∞—Ö"""
        try:
            # –ú–æ–Ω–≥–æ–ª + –ê–Ω–≥–ª–∏ “Ø—Å—ç–≥ —Ç–æ–æ
            config = '--oem 3 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789–ê–ë–í–ì–î–ï–ñ–ó–ò–ô–ö–õ–ú–ù”®–ü–†–°–¢–£“Æ–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø'

            # OCR —Ö–∏–π—Ö
            text = pytesseract.image_to_string(img, config=config, lang='eng')
            cleaned = self.clean_and_fix_text(text)

            if cleaned and self.is_valid_plate(cleaned):
                # Confidence —Ç–æ–æ—Ü–æ—Ö
                digit_count = sum(c.isdigit() for c in cleaned)
                letter_count = sum(c.isalpha() for c in cleaned)

                # –¢—ç–Ω—Ü–≤—ç—Ä—Ç—ç–π –±–∞–π—Ö —Ç—É—Å–∞–º —Å–∞–π–Ω
                balance = min(digit_count, letter_count) / \
                    max(digit_count, letter_count)
                conf = 60 + (balance * 30)

                return cleaned, conf
        except Exception as e:
            pass

        return None, 0

    def clean_and_fix_text(self, text):
        """–¢–µ–∫—Å—Ç —Ü—ç–≤—ç—Ä–ª—ç—Ö + –ë–£–†–£–£ —Ç—ç–º–¥—ç–≥—Ç –∑–∞—Å–∞—Ö"""
        # –ó–∞–π–ª—É—É–ª–∞—Ö
        text = text.strip()

        # –ó”©–≤—Ö”©–Ω “Ø—Å—ç–≥ —Ç–æ–æ
        cleaned = ''.join(c for c in text if c.isalnum())
        cleaned = cleaned.upper()

        # –ë–£–†–£–£ —Ç–∞–Ω–∏–ª—Ç –∑–∞—Å–∞—Ö - —ç–Ω—ç –º–∞—à —á—É—Ö–∞–ª!
        corrections = {
            'O': '0',  # O -> 0
            'I': '1',  # I -> 1
            'S': '5',  # S -> 5 (–∑–∞—Ä–∏–º–¥–∞–∞)
            'Z': '2',  # Z -> 2 (–∑–∞—Ä–∏–º–¥–∞–∞)
            'B': '8',  # B -> 8 (–∑–∞—Ä–∏–º–¥–∞–∞)
            'G': '6',  # G -> 6 (–º–∞–≥–∞–¥–≥“Ø–π)
        }

        # –•—ç—Ä—ç–≤ —Ç–æ–æ –∏—Ö –±–∞–π–≤–∞–ª “Ø—Å–≥–∏–π–≥ —Ç–æ–æ –±–æ–ª–≥–æ—Ö
        digit_count = sum(c.isdigit() for c in cleaned)
        total = len(cleaned)

        if total > 0 and digit_count / total > 0.5:  # 50%-–∞–∞—Å –∏–ª“Ø“Ø —Ç–æ–æ –±–æ–ª
            # “Æ—Å–≥“Ø“Ø–¥–∏–π–≥ —Ç–æ–æ –±–æ–ª–≥–æ—Ö
            result = []
            for c in cleaned:
                if c in corrections and c.isalpha():
                    result.append(corrections[c])
                else:
                    result.append(c)
            cleaned = ''.join(result)

        # –£—Ä—Ç —à–∞–ª–≥–∞—Ö
        if len(cleaned) < 5 or len(cleaned) > 10:
            return None

        return cleaned

    def draw_table(self, frame, video_fps):
        """–•“Ø—Å–Ω—ç–≥—Ç - VIDEO —Ü–∞–≥ —Ö–∞—Ä—É—É–ª–∞—Ö"""
        h, w = frame.shape[:2]
        table_w = 380
        table_x = w - table_w

        # –î—ç–≤—Å–≥—ç—Ä
        cv2.rectangle(frame, (table_x, 0), (w, h), (18, 18, 18), -1)

        # –ì–∞—Ä—á–∏–≥
        cv2.rectangle(frame, (table_x, 0), (w, 55), (0, 100, 0), -1)
        cv2.putText(frame, "TANISAN DUGAARUD",
                    (table_x + 60, 37), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255, 255, 255), 2)

        # –¢–æ–ª–≥–æ–π
        y = 75
        cv2.line(frame, (table_x + 10, y), (w - 10, y), (80, 80, 80), 2)
        y += 28

        cv2.putText(frame, "#", (table_x + 15, y),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, (180, 180, 180), 1)
        cv2.putText(frame, "Video Tsag", (table_x + 50, y),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, (180, 180, 180), 1)
        cv2.putText(frame, "Dugaar", (table_x + 160, y),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, (180, 180, 180), 1)
        cv2.putText(frame, "%", (table_x + 320, y),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, (180, 180, 180), 1)

        y += 8
        cv2.line(frame, (table_x + 10, y), (w - 10, y), (60, 60, 60), 1)

        # –ú”©—Ä“Ø“Ø–¥
        start_idx = max(0, len(self.detected_plates) - 9)
        for i, det in enumerate(self.detected_plates[start_idx:], start=start_idx+1):
            y += 38
            if y > h - 80:
                break

            # VIDEO —Ü–∞–≥ (—Å–µ–∫—É–Ω–¥—ç—ç—Å MM:SS –±–æ–ª–≥–æ—Ö)
            time_str = self.format_video_time(det['video_time'])
            plate = det['plate']
            conf = det['confidence']

            color = (0, 255, 0) if conf >= 75 else (0, 220, 220)

            # ‚Ññ
            cv2.putText(frame, f"{i}", (table_x + 15, y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)

            # VIDEO —Ü–∞–≥
            cv2.putText(frame, time_str, (table_x + 50, y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)

            # –î—É–≥–∞–∞—Ä
            cv2.putText(frame, plate, (table_x + 160, y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

            # Conf
            cv2.putText(frame, f"{conf:.0f}", (table_x + 320, y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫
        cv2.rectangle(frame, (table_x, h-60), (w, h), (28, 28, 28), -1)
        cv2.putText(frame, f"Niit olson: {len(self.detected_plates)}",
                    (table_x + 20, h - 32),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 100), 2)

        # Unique –¥—É–≥–∞–∞—Ä
        unique = len(set(d['plate'] for d in self.detected_plates))
        cv2.putText(frame, f"Unique: {unique}",
                    (table_x + 20, h - 8),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (100, 200, 255), 1)

        return frame

    def draw_detection(self, frame, x, y, w, h, text, conf):
        """–ò–ª—Ä“Ø“Ø–ª—ç–ª—Ç –∑—É—Ä–∞—Ö"""
        color = (0, 255, 0) if conf >= 75 else (0, 200, 255)
        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)

        if text:
            # –î—ç–≤—Å–≥—ç—Ä
            label = f"{text} ({conf:.0f}%)"
            (txt_w, txt_h), _ = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)

            cv2.rectangle(frame, (x, y-28), (x+txt_w+10, y), (0, 0, 0), -1)
            cv2.rectangle(frame, (x, y-28), (x+txt_w+10, y), color, 2)
            cv2.putText(frame, label, (x+5, y-8),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

        return frame

    def save_result(self, plate_img, text, video_time):
        """–•–∞–¥–≥–∞–ª–∞—Ö"""
        time_str = self.format_video_time(video_time)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # –§–∞–π–ª—ã–Ω –Ω—ç—Ä: –¥—É–≥–∞–∞—Ä_–≤–∏–¥–µ–æ–¶–∞–≥_timestamp
        filename = f"{text}_{time_str.replace(':', '-')}_{timestamp}.jpg"
        img_file = os.path.join(self.save_folder, filename)
        cv2.imwrite(img_file, plate_img)


def main():
    print("\n" + "="*70)
    print(" "*10 + "üöó –í–ò–î–ï–û –î–£–ì–ê–ê–† –¢–ê–ù–ò–• (–≠–¶–°–ò–ô–ù –•–£–í–ò–õ–ë–ê–†) üöó")
    print("="*70)
    print("\n‚ú® –°–∞–π–∂—Ä—É—É–ª–∞–ª—Ç:")
    print("  ‚Ä¢ –•—É—Ä–¥–∞–Ω –∞–∂–∏–ª–ª–∞–Ω–∞ (10 frame skip)")
    print("  ‚Ä¢ –î–∞–≤—Ö—Ü–∞–ª —Å–∞–π–Ω —à–∞–ª–≥–∞–Ω–∞ (60 frame gap)")
    print("  ‚Ä¢ –ë—É—Ä—É—É —Ç–∞–Ω–∏–ª—Ç –∑–∞—Å–Ω–∞ (O‚Üí0, I‚Üí1, –≥—ç—Ö –º—ç—Ç)")
    print("  ‚Ä¢ –í–∏–¥–µ–æ–Ω—ã —Ü–∞–≥ —Ö–∞—Ä—É—É–ª–Ω–∞ (MM:SS)")
    print("  ‚Ä¢ Unique –¥—É–≥–∞–∞—Ä —Ç–æ–æ–ª–Ω–æ")
    print("\n" + "-"*70 + "\n")

    detector = FastPlateDetector()

    print("üìÅ –í–∏–¥–µ–æ —Å–æ–Ω–≥–æ—Ö...")
    video_path = detector.select_video()

    if not video_path:
        print("‚ùå –í–∏–¥–µ–æ —Å–æ–Ω–≥–æ–≥–¥—Å–æ–Ω–≥“Ø–π!")
        return

    print(f"‚úÖ –í–∏–¥–µ–æ: {os.path.basename(video_path)}\n")

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("‚ùå –í–∏–¥–µ–æ –Ω—ç—ç–≥–¥—Å—ç–Ω–≥“Ø–π!")
        return

    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps == 0:
        fps = 30  # Default

    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    duration = total_frames / fps

    print(f"üìä –ú—ç–¥—ç—ç–ª—ç–ª:")
    print(f"   FPS: {fps:.1f}")
    print(f"   Resolution: {width}x{height}")
    print(f"   Frames: {total_frames}")
    print(f"   “Æ—Ä–≥—ç–ª–∂–ª—ç—Ö: {detector.format_video_time(duration)}\n")

    # Display size
    display_w = min(width, 1280)
    display_h = int(height * (display_w / width))

    print("üöÄ –≠—Ö—ç–ª–∂ –±–∞–π–Ω–∞...\n")
    print("   SPACE - –ó–æ–≥—Å–æ–æ—Ö/“Æ—Ä–≥—ç–ª–∂–ª“Ø“Ø–ª—ç—Ö")
    print("   Q - –î—É—É—Å–≥–∞—Ö\n")
    print("-"*70 + "\n")

    frame_count = 0
    paused = False

    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                print("\n‚úÖ –í–∏–¥–µ–æ –¥—É—É—Å–ª–∞–∞!")
                break

            frame_count += 1

            # –í–∏–¥–µ–æ–Ω—ã —Ü–∞–≥ (—Å–µ–∫—É–Ω–¥)
            video_time = frame_count / fps

            # Resize
            if frame.shape[1] != display_w:
                frame = cv2.resize(frame, (display_w, display_h))

            # 10 frame —Ç—É—Ç–∞–º–¥ —Ç–∞–Ω–∏—Ö (–ú–ê–ê–®–ì“Æ–ô –•–£–†–î–ê–ù)
            if frame_count % 10 == 0:
                plates = detector.detect_plates(frame)

                for (x, y, w, h) in plates:
                    plate_img = frame[y:y+h, x:x+w]

                    # –ë–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö + OCR
                    enhanced = detector.enhance_plate_fast(plate_img)
                    text, conf = detector.ocr_improved(enhanced)

                    # –ó”©–≤ –¥—É–≥–∞–∞—Ä + ”©–Ω–¥”©—Ä –∏—Ç–≥—ç–ª + –¥–∞–≤—Ö—Ü–∞–∞–≥“Ø–π
                    if text and conf >= detector.MIN_CONFIDENCE:
                        if not detector.is_duplicate(text, frame_count, video_time):
                            # –®–ò–ù–≠ –¥—É–≥–∞–∞—Ä
                            detector.detected_plates.append({
                                'plate': text,
                                'confidence': conf,
                                'video_time': video_time,
                                'frame': frame_count
                            })

                            detector.save_result(plate_img, text, video_time)

                            time_str = detector.format_video_time(video_time)
                            print(
                                f"‚úÖ {len(detector.detected_plates)}. {text} ({conf:.0f}%) @ {time_str}")

                        # –ó—É—Ä–∞—Ö
                        frame = detector.draw_detection(
                            frame, x, y, w, h, text, conf)

            # –•“Ø—Å–Ω—ç–≥—Ç
            frame = detector.draw_table(frame, fps)

            # –°—Ç–∞—Ç—É—Å
            h_frame = frame.shape[0]
            cv2.rectangle(frame, (5, h_frame-50),
                          (350, h_frame-5), (25, 25, 25), -1)

            # VIDEO —Ü–∞–≥
            curr_time_str = detector.format_video_time(video_time)
            total_time_str = detector.format_video_time(duration)
            cv2.putText(frame, f"Video: {curr_time_str} / {total_time_str}",
                        (10, h_frame-28),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (100, 200, 255), 2)

            # Progress
            progress = (frame_count / total_frames) * 100
            cv2.putText(frame, f"Progress: {progress:.1f}%",
                        (10, h_frame-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 255, 100), 1)

        cv2.imshow('Video Plate Detection', frame)

        key = cv2.waitKey(1) & 0xFF
        if key == ord('q') or key == ord('Q'):
            break
        elif key == ord(' '):
            paused = not paused
            print("‚è∏Ô∏è  –ó–æ–≥—Å–æ–æ—Å–æ–Ω" if paused else "‚ñ∂Ô∏è  “Æ—Ä–≥—ç–ª–∂–∏–ª–∂ –±–∞–π–Ω–∞")

    cap.release()
    cv2.destroyAllWindows()

    # –î“Ø–≥–Ω—ç–ª—Ç
    print("\n" + "="*70)
    print(" "*25 + "üìä –î“Æ–ì–ù–≠–õ–¢")
    print("="*70)
    print(f"–ù–∏–π—Ç —Ç–∞–Ω–∏–≥–¥—Å–∞–Ω: {len(detector.detected_plates)}")

    if detector.detected_plates:
        unique_plates = set(d['plate'] for d in detector.detected_plates)
        print(f"Unique –¥—É–≥–∞–∞—Ä: {len(unique_plates)}")

        print(f"\nüìã –ë“Ø—Ö –¥—É–≥–∞–∞—Ä—É—É–¥:")
        for i, det in enumerate(detector.detected_plates, 1):
            time_str = detector.format_video_time(det['video_time'])
            print(
                f"  {i}. {det['plate']} ({det['confidence']:.0f}%) @ {time_str}")

        avg_conf = sum(d['confidence']
                       for d in detector.detected_plates) / len(detector.detected_plates)
        print(f"\n–î—É–Ω–¥–∞–∂ confidence: {avg_conf:.1f}%")

    print(f"\nüíæ –§–∞–π–ª—É—É–¥: {detector.save_folder}/")
    print("\nüëã –ë–∞—è—Ä—Ç–∞–π!")
    print("="*70 + "\n")


if __name__ == "__main__":
    main()
