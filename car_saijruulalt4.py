import cv2
import numpy as np
import pytesseract
from datetime import datetime
import os
from collections import deque
import tkinter as tk
from tkinter import filedialog

# Tesseract –∑–∞–º
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

class VideoPlateDetector:
    def __init__(self):
        # –•–∞–≤—Ç–∞—Å “Ø“Ø—Å–≥—ç—Ö
        self.save_folder = "detected_plates"
        if not os.path.exists(self.save_folder):
            os.makedirs(self.save_folder)
        
        # –î—É–≥–∞–∞—Ä –∏–ª—Ä“Ø“Ø–ª—ç—Ö classifier
        self.cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_russian_plate_number.xml'
        )
        
        # –•“Ø—Å–Ω—ç–≥—Ç –º—ç–¥—ç—ç–ª—ç–ª
        self.detected_plates = []  # [{time, plate, confidence, image}]
        
        # –î–∞–≤—Ö—Ü–∞—Ö “Ø–µ–¥ –∞–ª–≥–∞—Å–∞—Ö
        self.recent_plates = deque(maxlen=5)
        
        print("‚úÖ –°–∏—Å—Ç–µ–º –±—ç–ª—ç–Ω!")
    
    def select_video(self):
        """–í–∏–¥–µ–æ —Ñ–∞–π–ª —Å–æ–Ω–≥–æ—Ö"""
        root = tk.Tk()
        root.withdraw()
        video_path = filedialog.askopenfilename(
            title="–í–∏–¥–µ–æ —Å–æ–Ω–≥–æ—Ö",
            filetypes=[
                ("Video files", "*.mp4 *.avi *.mov *.mkv"),
                ("All files", "*.*")
            ]
        )
        root.destroy()
        return video_path
    
    def is_duplicate(self, text):
        """–î–∞–≤—Ö—Ü—Å–∞–Ω —ç—Å—ç—Ö–∏–π–≥ —à–∞–ª–≥–∞—Ö"""
        if not text or len(text) < 3:
            return True
        return text in self.recent_plates
    
    def detect_plates(self, frame):
        """–î—É–≥–∞–∞—Ä –∏–ª—Ä“Ø“Ø–ª—ç—Ö - —Å–∞–π–∂—Ä—É—É–ª—Å–∞–Ω"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # Contrast —Å–∞–π–∂—Ä—É—É–ª–∞—Ö
        gray = cv2.equalizeHist(gray)
        
        # –û–ª–æ–Ω —Ö—ç–º–∂—ç—ç—Å—ç—ç—Ä —Ö–∞–π—Ö
        plates = self.cascade.detectMultiScale(
            gray, 
            scaleFactor=1.05,  # –ò–ª“Ø“Ø –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª—Ç–∞–π
            minNeighbors=3,     # –ò–ª“Ø“Ø –æ–ª–æ–Ω –¥—É–≥–∞–∞—Ä –æ–ª–æ—Ö
            minSize=(60, 20),   # –ë–∞–≥–∞ –¥—É–≥–∞–∞—Ä —á —Ç–∞–Ω–∏—Ö
            maxSize=(400, 150)
        )
        return plates
    
    def preprocess_plate(self, plate_img):
        """–ó—É—Ä–∞–≥ –ú–ê–® —Å–∞–π–Ω –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö"""
        # RGB -> Gray
        if len(plate_img.shape) == 3:
            gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)
        else:
            gray = plate_img.copy()
        
        # 1. –¢–æ–º –±–æ–ª–≥–æ—Ö (–ú–ê–ê–®–ì“Æ–ô –¢–û–ú)
        h, w = gray.shape
        scale = 200 / h  # 200 pixel ”©–Ω–¥”©—Ä –±–æ–ª–≥–æ—Ö
        new_w = int(w * scale)
        gray = cv2.resize(gray, (new_w, 200), interpolation=cv2.INTER_CUBIC)
        
        # 2. Denoise - —Ö“Ø—á—Ç—ç–π
        gray = cv2.fastNlMeansDenoising(gray, h=10)
        
        # 3. Contrast ”©—Å–≥”©—Ö
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        gray = clahe.apply(gray)
        
        # 4. Sharpening
        kernel = np.array([[-1,-1,-1],
                          [-1, 9,-1],
                          [-1,-1,-1]])
        gray = cv2.filter2D(gray, -1, kernel)
        
        # 5. Morphology
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        gray = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)
        
        # 6. Adaptive threshold (OTSU-–∞–∞—Å –¥—ç—ç—Ä)
        binary = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY, 11, 2
        )
        
        # 7. –î–∞—Ö–∏–Ω denoise
        binary = cv2.medianBlur(binary, 3)
        
        return binary
    
    def recognize_text(self, plate_img):
        """OCR - ”©–Ω–¥”©—Ä –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª—Ç–∞–π"""
        try:
            # –ë–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö
            processed = self.preprocess_plate(plate_img)
            
            # –û–ª–æ–Ω config —Ç—É—Ä—à–∏–Ω–∞
            configs = [
                '--oem 3 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',
                '--oem 3 --psm 8 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',
                '--oem 3 --psm 11 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',
                '--oem 1 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',
            ]
            
            results = []
            for config in configs:
                try:
                    # –≠—Ö –∑—É—Ä–∞–≥
                    text1 = pytesseract.image_to_string(processed, config=config)
                    cleaned1 = self.clean_text(text1)
                    if cleaned1 and len(cleaned1) >= 4:
                        results.append(cleaned1)
                    
                    # –£—Ä–≤—É—É –∑—É—Ä–∞–≥ (—Ü–∞–≥–∞–∞–Ω –¥—ç—ç—Ä —Ö–∞—Ä)
                    inverted = cv2.bitwise_not(processed)
                    text2 = pytesseract.image_to_string(inverted, config=config)
                    cleaned2 = self.clean_text(text2)
                    if cleaned2 and len(cleaned2) >= 4:
                        results.append(cleaned2)
                except:
                    pass
            
            # –•–∞–º–≥–∏–π–Ω –∏—Ö –¥–∞–≤—Ç–∞–≥–¥—Å–∞–Ω
            if results:
                from collections import Counter
                counter = Counter(results)
                best_text, count = counter.most_common(1)[0]
                
                # –ò—Ç–≥—ç–ª—Ç—ç–π —ç—Å—ç—Ö–∏–π–≥ —Ç–æ–æ—Ü–æ—Ö
                confidence = (count / len(results)) * 100 if results else 0
                
                return best_text, confidence
        except Exception as e:
            print(f"   ‚ö†Ô∏è  OCR –∞–ª–¥–∞–∞: {e}")
        
        return None, 0
    
    def clean_text(self, text):
        """–¢–µ–∫—Å—Ç —Ü—ç–≤—ç—Ä–ª—ç—Ö"""
        # –ó”©–≤—Ö”©–Ω “Ø—Å—ç–≥ —Ç–æ–æ
        cleaned = ''.join(c for c in text if c.isalnum())
        cleaned = cleaned.upper().strip()
        
        # –•—ç—Ç –±–æ–≥–∏–Ω–æ —ç—Å–≤—ç–ª —É—Ä—Ç –±–æ–ª –∞–ª–≥–∞—Å–∞—Ö
        if len(cleaned) < 4 or len(cleaned) > 12:
            return None
        
        return cleaned
    
    def draw_table(self, frame):
        """–•“Ø—Å–Ω—ç–≥—Ç –∑—É—Ä–∞—Ö - –±–∞—Ä—É—É–Ω —Ç–∞–ª–¥"""
        h, w = frame.shape[:2]
        
        # –•“Ø—Å–Ω—ç–≥—Ç–∏–π–Ω ”©—Ä–≥”©–Ω
        table_width = 350
        table_x = w - table_width
        
        # –•–∞—Ä –¥—ç–≤—Å–≥—ç—Ä
        overlay = frame.copy()
        cv2.rectangle(overlay, (table_x, 0), (w, h), (20, 20, 20), -1)
        cv2.addWeighted(overlay, 0.85, frame, 0.15, 0, frame)
        
        # –ì–∞—Ä—á–∏–≥
        cv2.rectangle(frame, (table_x, 0), (w, 50), (0, 100, 200), -1)
        cv2.putText(frame, "TANISAN DUGAARUD", 
                   (table_x + 10, 32), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255, 255, 255), 2)
        
        # –•“Ø—Å–Ω—ç–≥—Ç–∏–π–Ω —Ç–æ–ª–≥–æ–π
        y = 60
        cv2.line(frame, (table_x, y), (w, y), (100, 100, 100), 2)
        cv2.putText(frame, "Tsag", (table_x + 10, y + 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
        cv2.putText(frame, "Dugaar", (table_x + 100, y + 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
        cv2.putText(frame, "%", (table_x + 280, y + 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
        
        y += 35
        cv2.line(frame, (table_x, y), (w, y), (100, 100, 100), 1)
        
        # –ú”©—Ä“Ø“Ø–¥ —Ö–∞—Ä—É—É–ª–∞—Ö (—Å“Ø“Ø–ª–∏–π–Ω 12)
        start_idx = max(0, len(self.detected_plates) - 12)
        for i, detection in enumerate(self.detected_plates[start_idx:]):
            y += 40
            if y > h - 20:
                break
            
            time_str = detection['time'].strftime("%H:%M:%S")
            plate = detection['plate']
            conf = detection['confidence']
            
            # –¶–∞–≥
            cv2.putText(frame, time_str, (table_x + 10, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
            
            # –î—É–≥–∞–∞—Ä (”©–Ω–≥”©—Ç—ç–π)
            color = (0, 255, 0) if conf > 70 else (0, 200, 255) if conf > 40 else (0, 100, 255)
            cv2.putText(frame, plate, (table_x + 100, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)
            
            # Confidence
            cv2.putText(frame, f"{conf:.0f}", (table_x + 280, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫ –¥–æ–æ–¥ —Ö—ç—Å—ç–≥—Ç
        cv2.rectangle(frame, (table_x, h - 60), (w, h), (40, 40, 40), -1)
        cv2.putText(frame, f"Niit: {len(self.detected_plates)}", 
                   (table_x + 10, h - 35), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 100), 1)
        
        high_conf = sum(1 for d in self.detected_plates if d['confidence'] > 70)
        cv2.putText(frame, f"Ondor: {high_conf}", 
                   (table_x + 10, h - 12), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 100), 1)
        
        return frame
    
    def draw_detection(self, frame, x, y, w, h, text, confidence):
        """–î—É–≥–∞–∞—Ä –¥—ç—ç—Ä —Ö“Ø—Ä—ç—ç"""
        # ”®–Ω–≥”© confidence-–∞–∞—Å —Ö–∞–º–∞–∞—Ä–Ω–∞
        if confidence > 70:
            color = (0, 255, 0)  # –ù–æ–≥–æ–æ–Ω
        elif confidence > 40:
            color = (0, 200, 255)  # –®–∞—Ä
        else:
            color = (0, 100, 255)  # –£–ª–∞–∞–Ω
        
        # –•“Ø—Ä—ç—ç
        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
        
        # –î—ç–≤—Å–≥—ç—Ä + —Ç–µ–∫—Å—Ç
        if text:
            label = f"{text} ({confidence:.0f}%)"
            text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
            
            cv2.rectangle(frame, (x, y-30), (x + text_size[0] + 10, y), (0, 0, 0), -1)
            cv2.rectangle(frame, (x, y-30), (x + text_size[0] + 10, y), color, 2)
            
            cv2.putText(frame, label, (x + 5, y - 8), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        return frame
    
    def save_to_file(self):
        """Excel —Ñ–∞–π–ª “Ø“Ø—Å–≥—ç—Ö"""
        if not self.detected_plates:
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        txt_file = os.path.join(self.save_folder, f"report_{timestamp}.txt")
        
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write("="*60 + "\n")
            f.write("–ú–ê–®–ò–ù–´ –î–£–ì–ê–ê–† –¢–ê–ù–ò–• - –¢–ê–ô–õ–ê–ù\n")
            f.write("="*60 + "\n\n")
            f.write(f"–û–≥–Ω–æ–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"–ù–∏–π—Ç —Ç–∞–Ω–∏–≥–¥—Å–∞–Ω: {len(self.detected_plates)}\n\n")
            f.write("-"*60 + "\n")
            f.write(f"{'‚Ññ':<5} {'–¶–∞–≥':<12} {'–î—É–≥–∞–∞—Ä':<15} {'–ò—Ç–≥—ç–ª—Ç':<10}\n")
            f.write("-"*60 + "\n")
            
            for i, det in enumerate(self.detected_plates, 1):
                time_str = det['time'].strftime("%H:%M:%S")
                f.write(f"{i:<5} {time_str:<12} {det['plate']:<15} {det['confidence']:.1f}%\n")
        
        print(f"\nüíæ –¢–∞–π–ª–∞–Ω —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞: {txt_file}")

def main():
    print("\n" + "="*70)
    print(" "*15 + "üöó –í–ò–î–ï–û –î–£–ì–ê–ê–† –¢–ê–ù–ò–• (–•“Æ–°–ù–≠–ì–¢–¢–≠–ô) üöó")
    print("="*70)
    print("\nüìå –û–Ω—Ü–ª–æ–≥:")
    print("  ‚úì –í–∏–¥–µ–æ —Ñ–∞–π–ª–∞–∞—Å –¥—É–≥–∞–∞—Ä —Ç–∞–Ω–∏—Ö")
    print("  ‚úì –ë–∞—Ä—É—É–Ω —Ç–∞–ª–¥ —Ö“Ø—Å–Ω—ç–≥—Ç —Ö–∞—Ä—É—É–ª–∞—Ö")
    print("  ‚úì ”®–Ω–¥”©—Ä –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª—Ç–∞–π OCR")
    print("  ‚úì Confidence —Ö—É–≤—å —Ö–∞—Ä—É—É–ª–∞—Ö")
    print("  ‚úì –¢–∞–π–ª–∞–Ω “Ø“Ø—Å–≥—ç—Ö")
    print("\n" + "-"*70 + "\n")
    
    detector = VideoPlateDetector()
    
    # –í–∏–¥–µ–æ —Å–æ–Ω–≥–æ—Ö
    print("üìÅ –í–∏–¥–µ–æ —Ñ–∞–π–ª —Å–æ–Ω–≥–æ—Ö —Ü–æ–Ω—Ö –Ω—ç—ç–≥–¥—ç–Ω—ç...")
    video_path = detector.select_video()
    
    if not video_path:
        print("‚ùå –í–∏–¥–µ–æ —Å–æ–Ω–≥–æ–≥–¥—Å–æ–Ω–≥“Ø–π!")
        return
    
    print(f"‚úÖ –í–∏–¥–µ–æ: {os.path.basename(video_path)}\n")
    
    # –í–∏–¥–µ–æ –Ω—ç—ç—Ö
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("‚ùå –í–∏–¥–µ–æ –Ω—ç—ç–≥–¥—Å—ç–Ω–≥“Ø–π!")
        return
    
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"üé¨ FPS: {fps} | –ù–∏–π—Ç frame: {total_frames}")
    print(f"‚è±Ô∏è  “Æ—Ä–≥—ç–ª–∂–ª—ç—Ö —Ö—É–≥–∞—Ü–∞–∞: {total_frames/fps:.1f} —Å–µ–∫—É–Ω–¥\n")
    print("üöÄ –¢–∞–Ω–∏—Ö —ç—Ö—ç–ª–ª—ç—ç...\n")
    print("   SPACE - –¢“Ø—Ä –∑–æ–≥—Å–æ–æ—Ö/“Æ—Ä–≥—ç–ª–∂–ª“Ø“Ø–ª—ç—Ö")
    print("   Q - –î—É—É—Å–≥–∞—Ö\n")
    print("-"*70 + "\n")
    
    frame_count = 0
    paused = False
    
    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                print("\n‚úÖ –í–∏–¥–µ–æ –¥—É—É—Å–ª–∞–∞!")
                break
            
            frame_count += 1
            
            # –¢–æ–º resolution –±–æ–ª –±–∞–≥–∞—Å–≥–∞—Ö
            h, w = frame.shape[:2]
            if w > 1280:
                scale = 1280 / w
                frame = cv2.resize(frame, (1280, int(h * scale)))
            
            # 5 frame —Ç—É—Ç–∞–º–¥ —Ç–∞–Ω–∏—Ö (—Ö—É—Ä–¥ –Ω—ç–º—ç—Ö)
            if frame_count % 5 == 0:
                plates = detector.detect_plates(frame)
                
                for (x, y, w_p, h_p) in plates:
                    plate_img = frame[y:y+h_p, x:x+w_p]
                    
                    # OCR
                    text, confidence = detector.recognize_text(plate_img)
                    
                    if text and not detector.is_duplicate(text):
                        # –•–∞–¥–≥–∞–ª–∞—Ö
                        detector.detected_plates.append({
                            'time': datetime.now(),
                            'plate': text,
                            'confidence': confidence,
                            'image': plate_img.copy()
                        })
                        detector.recent_plates.append(text)
                        
                        print(f"‚úÖ –®–∏–Ω—ç: {text} ({confidence:.0f}%) | –ù–∏–π—Ç: {len(detector.detected_plates)}")
                    
                    # –ó—É—Ä–∞—Ö
                    if text:
                        frame = detector.draw_detection(frame, x, y, w_p, h_p, text, confidence)
            
            # –•“Ø—Å–Ω—ç–≥—Ç –∑—É—Ä–∞—Ö
            frame = detector.draw_table(frame)
            
            # Progress
            progress = (frame_count / total_frames) * 100
            cv2.putText(frame, f"Progress: {progress:.1f}%", 
                       (10, frame.shape[0] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (100, 200, 100), 2)
        
        cv2.imshow('Video Dugaar Tanikh', frame)
        
        key = cv2.waitKey(1 if not paused else 0) & 0xFF
        if key == ord('q') or key == ord('Q'):
            break
        elif key == ord(' '):
            paused = not paused
            print("‚è∏Ô∏è  –ó–æ–≥—Å–æ–æ—Å–æ–Ω" if paused else "‚ñ∂Ô∏è  “Æ—Ä–≥—ç–ª–∂–∏–ª–∂ –±–∞–π–Ω–∞")
    
    cap.release()
    cv2.destroyAllWindows()
    
    # –¢–∞–π–ª–∞–Ω —Ö–∞–¥–≥–∞–ª–∞—Ö
    if detector.detected_plates:
        detector.save_to_file()
    
    # –î“Ø–≥–Ω—ç–ª—Ç
    print("\n" + "="*70)
    print(" "*25 + "üìä –î“Æ–ì–ù–≠–õ–¢")
    print("="*70)
    print(f"–ù–∏–π—Ç —Ç–∞–Ω–∏–≥–¥—Å–∞–Ω: {len(detector.detected_plates)}")
    
    high_conf = sum(1 for d in detector.detected_plates if d['confidence'] > 70)
    med_conf = sum(1 for d in detector.detected_plates if 40 <= d['confidence'] <= 70)
    low_conf = sum(1 for d in detector.detected_plates if d['confidence'] < 40)
    
    print(f"”®–Ω–¥”©—Ä –∏—Ç–≥—ç–ª—Ç—Ç—ç–π (>70%): {high_conf}")
    print(f"–î—É–Ω–¥ –∏—Ç–≥—ç–ª—Ç—Ç—ç–π (40-70%): {med_conf}")
    print(f"–ë–∞–≥–∞ –∏—Ç–≥—ç–ª—Ç—Ç—ç–π (<40%): {low_conf}")
    
    print(f"\nüíæ –§–∞–π–ª—É—É–¥: {detector.save_folder}/")
    print("\nüëã –ë–∞—è—Ä—Ç–∞–π!")
    print("="*70 + "\n")

if __name__ == "__main__":
    main()