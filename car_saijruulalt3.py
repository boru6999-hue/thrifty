import cv2
import numpy as np
import pytesseract
from datetime import datetime
import os
from collections import deque

# Tesseract –∑–∞–º
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

class AutoPlateDetector:
    def __init__(self):
        # –•–∞–≤—Ç–∞—Å “Ø“Ø—Å–≥—ç—Ö
        self.save_folder = "detected_plates"
        if not os.path.exists(self.save_folder):
            os.makedirs(self.save_folder)
        
        # –î—É–≥–∞–∞—Ä –∏–ª—Ä“Ø“Ø–ª—ç—Ö classifier
        self.cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_russian_plate_number.xml'
        )
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫
        self.total_detected = 0
        self.successful_reads = 0
        
        # –°“Ø“Ø–ª–¥ —Ç–∞–Ω—å—Å–∞–Ω –¥—É–≥–∞–∞—Ä—É—É–¥ (–¥–∞–≤—Ö—Ü–∞—Ö “Ø–µ–¥ —Ç–∞–Ω—å—Ö–≥“Ø–π –±–∞–π—Ö)
        self.recent_plates = deque(maxlen=10)
        
        # –û–¥–æ–æ —Ç–∞–Ω—å–∂ –±—É–π –¥—É–≥–∞–∞—Ä—É—É–¥
        self.current_detections = []
        
        print("‚úÖ –ê–≤—Ç–æ–º–∞—Ç —Ç–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º –±—ç–ª—ç–Ω!")
    
    def is_duplicate(self, text, threshold=0.8):
        """–î–∞–≤—Ö—Ü—Å–∞–Ω –¥—É–≥–∞–∞—Ä —ç—Å—ç—Ö–∏–π–≥ —à–∞–ª–≥–∞—Ö"""
        if not text or text == "Unknown":
            return False
            
        for recent in self.recent_plates:
            if recent == text:
                return True
            # –ò–∂–∏–ª —Ç”©—Å—Ç—ç–π —ç—Å—ç—Ö–∏–π–≥ —à–∞–ª–≥–∞—Ö
            similarity = sum(a == b for a, b in zip(text, recent)) / max(len(text), len(recent))
            if similarity > threshold:
                return True
        return False
    
    def detect_plates(self, frame):
        """–î—É–≥–∞–∞—Ä –∏–ª—Ä“Ø“Ø–ª—ç—Ö"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        plates = self.cascade.detectMultiScale(gray, 1.1, 4, minSize=(50, 20))
        return plates
    
    def preprocess_plate(self, plate_img):
        """–ó—É—Ä–∞–≥ —Å–∞–π–∂—Ä—É—É–ª–∞—Ö"""
        gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)
        
        # –¢–æ–º—Ä—É—É–ª–∞—Ö
        h, w = gray.shape
        if h < 100:
            scale = 100 / h
            new_w = int(w * scale)
            gray = cv2.resize(gray, (new_w, 100))
        
        # Noise –∞—Ä–∏–ª–≥–∞—Ö
        denoised = cv2.fastNlMeansDenoising(gray)
        
        # OTSU threshold
        _, binary = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        return binary
    
    def recognize_text(self, plate_img):
        """OCR - —Ö—ç–¥ —Ö—ç–¥—ç–Ω –∞—Ä–≥–∞–∞—Ä —Ç—É—Ä—à–∏–Ω–∞"""
        try:
            processed = self.preprocess_plate(plate_img)
            
            configs = [
                '--oem 3 --psm 7',
                '--oem 3 --psm 8',
                '--oem 3 --psm 11'
            ]
            
            results = []
            for config in configs:
                try:
                    text = pytesseract.image_to_string(processed, config=config)
                    cleaned = self.clean_text(text)
                    if cleaned and len(cleaned) >= 3:
                        results.append(cleaned)
                except:
                    pass
            
            if results:
                from collections import Counter
                counter = Counter(results)
                best_text = counter.most_common(1)[0][0]
                return best_text
        except:
            pass
        
        return None
    
    def clean_text(self, text):
        """–¢–µ–∫—Å—Ç —Ü—ç–≤—ç—Ä–ª—ç—Ö"""
        cleaned = ''.join(c for c in text if c.isalnum())
        return cleaned.upper().strip()
    
    def draw_detection_box(self, frame, x, y, w, h, text, is_new):
        """–î—É–≥–∞–∞—Ä –¥—ç—ç—Ä —Ö“Ø—Ä—ç—ç –∑—É—Ä–∞—Ö"""
        # ”®–Ω–≥”©: —à–∏–Ω—ç –±–æ–ª –Ω–æ–≥–æ–æ–Ω, —Ö—É—É—á–∏–Ω –±–æ–ª —à–∞—Ä
        color = (0, 255, 0) if is_new else (0, 200, 255)
        
        # –•“Ø—Ä—ç—ç
        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 3)
        
        # –î—É–≥–∞–∞—Ä—ã–Ω —Ç–µ–∫—Å—Ç (—Ç–æ–º, —Ö–∞—Ä –¥—ç–≤—Å–≥—ç—Ä –¥—ç—ç—Ä)
        if text and text != "Unknown":
            # –î—ç–≤—Å–≥—ç—Ä
            text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_DUPLEX, 1.2, 2)[0]
            bg_x1 = x
            bg_y1 = y - 45
            bg_x2 = x + text_size[0] + 20
            bg_y2 = y - 5
            
            cv2.rectangle(frame, (bg_x1, bg_y1), (bg_x2, bg_y2), (0, 0, 0), -1)
            cv2.rectangle(frame, (bg_x1, bg_y1), (bg_x2, bg_y2), color, 2)
            
            # –¢–µ–∫—Å—Ç
            cv2.putText(frame, text, (x + 10, y - 15), 
                       cv2.FONT_HERSHEY_DUPLEX, 1.2, color, 2)
        
        return frame
    
    def create_detection_window(self, plate_img, text):
        """–¢–æ–º —Ö–∞—Ä—É—É–ª–∞—Ö —Ü–æ–Ω—Ö “Ø“Ø—Å–≥—ç—Ö"""
        h, w = plate_img.shape[:2]
        
        # –¢–æ–º –±–æ–ª–≥–æ—Ö (400px ”©–Ω–¥”©—Ä)
        scale = 200 / h
        new_w = int(w * scale)
        new_h = 200
        enlarged = cv2.resize(plate_img, (new_w, new_h))
        
        # –¶–æ–Ω—Ö–Ω—ã —Ö—ç–º–∂—ç—ç
        window_h = new_h + 120
        window_w = max(new_w, 400)
        
        # –•–∞—Ä –¥—ç–≤—Å–≥—ç—Ä “Ø“Ø—Å–≥—ç—Ö
        window = np.zeros((window_h, window_w, 3), dtype=np.uint8)
        window[:] = (30, 30, 30)
        
        # –ó—É—Ä–∞–≥ —Ç–∞–≤–∏—Ö
        x_offset = (window_w - new_w) // 2
        window[10:10+new_h, x_offset:x_offset+new_w] = enlarged
        
        # –î—É–≥–∞–∞—Ä –±–∏—á–∏—Ö
        text_y = new_h + 40
        if text and text != "Unknown":
            cv2.putText(window, text, (20, text_y), 
                       cv2.FONT_HERSHEY_DUPLEX, 1.5, (0, 255, 0), 3)
        else:
            cv2.putText(window, "Tanigdsan gui", (20, text_y), 
                       cv2.FONT_HERSHEY_DUPLEX, 1.2, (0, 100, 255), 2)
        
        # –û–≥–Ω–æ–æ
        time_now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        cv2.putText(window, time_now, (20, text_y + 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (150, 150, 150), 1)
        
        return window
    
    def save_detection(self, plate_img, text):
        """–î—É–≥–∞–∞—Ä —Ö–∞–¥–≥–∞–ª–∞—Ö"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        
        img_file = os.path.join(self.save_folder, f"plate_{timestamp}.jpg")
        cv2.imwrite(img_file, plate_img)
        
        txt_file = os.path.join(self.save_folder, f"plate_{timestamp}.txt")
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(f"–û–≥–Ω–æ–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"–î—É–≥–∞–∞—Ä: {text if text else '–¢–∞–Ω–∏–≥–¥—Å–∞–Ω–≥“Ø–π'}\n")
        
        return img_file
    
    def draw_ui(self, frame):
        """UI —ç–ª–µ–º–µ–Ω—Ç“Ø“Ø–¥"""
        h, w = frame.shape[:2]
        
        # –î—ç—ç–¥ —Ö—ç—Å—ç–≥ - —Å—Ç–∞—Ç—É—Å
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (w, 70), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        cv2.putText(frame, "AVTOMAAT DUGAAR TANIKH", 
                   (20, 30), cv2.FONT_HERSHEY_DUPLEX, 0.9, (0, 255, 255), 2)
        
        stats = f"Niit: {self.total_detected} | Amjilttai: {self.successful_reads}"
        cv2.putText(frame, stats, 
                   (20, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (100, 255, 100), 1)
        
        # Q —Ç–æ–≤—á –∑–∞–∞–≤–∞—Ä
        cv2.putText(frame, "Q - Garah", 
                   (w - 150, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return frame

def main():
    print("\n" + "="*70)
    print(" "*15 + "üöó –ê–í–¢–û–ú–ê–¢ –ú–ê–®–ò–ù–´ –î–£–ì–ê–ê–† –¢–ê–ù–ò–• üöó")
    print("="*70)
    print("\nüìå –û–Ω—Ü–ª–æ–≥:")
    print("  ‚úì –ö–∞–º–µ—Ä–∞–∞—Å —à—É—É–¥ —Ç–∞–Ω–∏—Ö")
    print("  ‚úì –ú–∞—à–∏–Ω –≥–∞—Ä—á –∏—Ä—ç—Ö “Ø–µ–¥ –∞–≤—Ç–æ–º–∞—Ç–∞–∞—Ä —Ç–∞–Ω–∏—Ö")
    print("  ‚úì –î—É–≥–∞–∞—Ä—ã–≥ —Ç–æ–º —Ö–∞—Ä—É—É–ª–∞—Ö")
    print("  ‚úì –ê–≤—Ç–æ–º–∞—Ç–∞–∞—Ä —Ö–∞–¥–≥–∞–ª–∞—Ö")
    print("  ‚úì –î–∞–≤—Ö—Ü—Å–∞–Ω –¥—É–≥–∞–∞—Ä –∞–ª–≥–∞—Å–∞—Ö")
    print("\n" + "-"*70 + "\n")
    
    # –ö–∞–º–µ—Ä —ç—Ö–ª“Ø“Ø–ª—ç—Ö
    print("üé• –ö–∞–º–µ—Ä —Ö–æ–ª–±–æ–≥–¥–æ–∂ –±–∞–π–Ω–∞...")
    cap = None
    for i in [0, 1, 2]:
        test_cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)
        if test_cap.isOpened():
            ret, _ = test_cap.read()
            if ret:
                cap = test_cap
                print(f"‚úÖ –ö–∞–º–µ—Ä #{i} —Ö–æ–ª–±–æ–≥–¥–ª–æ–æ!\n")
                break
            test_cap.release()
    
    if not cap:
        print("‚ùå –ö–∞–º–µ—Ä –æ–ª–¥—Å–æ–Ω–≥“Ø–π!")
        return
    
    # Resolution —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    
    detector = AutoPlateDetector()
    
    print("üöÄ –°–ò–°–¢–ï–ú–ò–ô–ì –≠–•–õ“Æ“Æ–õ–ñ –ë–ê–ô–ù–ê...")
    print("   –ú–∞—à–∏–Ω—ã –¥—É–≥–∞–∞—Ä—ã–≥ –∫–∞–º–µ—Ä —Ä—É—É —Ö–∞—Ä—É—É–ª–∞–∞—Ä–∞–π")
    print("   –ê–≤—Ç–æ–º–∞—Ç–∞–∞—Ä —Ç–∞–Ω–∏–∂, —Ç–æ–º —Ö–∞—Ä—É—É–ª–Ω–∞")
    print("   'Q' —Ç–æ–≤—á –¥–∞—Ä–∂ –≥–∞—Ä–∞—Ö\n")
    print("-"*70 + "\n")
    
    frame_count = 0
    detection_windows = {}  # –•–∞–¥–≥–∞–ª—Å–∞–Ω —Ü–æ–Ω—Ö–Ω—É—É–¥
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_count += 1
        
        # –ö–∞–º–µ—Ä—ã–≥ —ç—Ä–≥“Ø“Ø–ª—ç—Ö (—Ö—ç—Ä—ç–≤ —à–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π –±–æ–ª)
        frame = cv2.flip(frame, 1)
        
        # 3 frame —Ç—É—Ç–∞–º–¥ –ª —Ç–∞–Ω–∏—Ö (—Ö—É—Ä–¥ –Ω—ç–º—ç—Ö)
        if frame_count % 3 == 0:
            plates = detector.detect_plates(frame)
            
            for (x, y, w, h) in plates:
                # –î—É–≥–∞–∞—Ä—ã–Ω —Ö—ç—Å—ç–≥ —Ç–∞—Å–ª–∞—Ö
                plate_img = frame[y:y+h, x:x+w]
                
                # OCR —Ö–∏–π—Ö
                text = detector.recognize_text(plate_img)
                
                # –®–∏–Ω—ç –¥—É–≥–∞–∞—Ä —ç—Å—ç—Ö–∏–π–≥ —à–∞–ª–≥–∞—Ö
                is_new = False
                if text and not detector.is_duplicate(text):
                    is_new = True
                    detector.total_detected += 1
                    detector.recent_plates.append(text)
                    
                    if text != "Unknown":
                        detector.successful_reads += 1
                        
                        # –•–∞–¥–≥–∞–ª–∞—Ö
                        detector.save_detection(plate_img, text)
                        
                        # –ö–æ–Ω—Å–æ–ª–¥ —Ö—ç–≤–ª—ç—Ö
                        print(f"‚úÖ –®–∏–Ω—ç –¥—É–≥–∞–∞—Ä: {text} | –ù–∏–π—Ç: {detector.total_detected}")
                        
                        # –¢–æ–º —Ö–∞—Ä—É—É–ª–∞—Ö —Ü–æ–Ω—Ö “Ø“Ø—Å–≥—ç—Ö
                        window = detector.create_detection_window(plate_img, text)
                        window_name = f"Dugaar - {text}"
                        
                        # –¶–æ–Ω—Ö —Ö–∞—Ä—É—É–ª–∞—Ö
                        cv2.imshow(window_name, window)
                        detection_windows[window_name] = True
                
                # –î—É–≥–∞–∞—Ä –¥—ç—ç—Ä —Ö“Ø—Ä—ç—ç –∑—É—Ä–∞—Ö
                frame = detector.draw_detection_box(frame, x, y, w, h, text, is_new)
        
        # UI –∑—É—Ä–∞—Ö
        frame = detector.draw_ui(frame)
        
        # “Æ–Ω–¥—Å—ç–Ω —Ü–æ–Ω—Ö
        cv2.imshow('Avtomaat Tanikh Sistem', frame)
        
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q') or key == ord('Q'):
            break
    
    # –î—É—É—Å–≥–∞–≤–∞—Ä
    cap.release()
    cv2.destroyAllWindows()
    
    # –î“Ø–≥–Ω—ç–ª—Ç
    print("\n" + "="*70)
    print(" "*25 + "üìä –î“Æ–ì–ù–≠–õ–¢")
    print("="*70)
    print(f"–ù–∏–π—Ç –∏–ª—Ä“Ø“Ø–ª—Å—ç–Ω: {detector.total_detected}")
    print(f"–ê–º–∂–∏–ª—Ç—Ç–∞–π —É–Ω—à—Å–∞–Ω: {detector.successful_reads}")
    if detector.total_detected > 0:
        accuracy = (detector.successful_reads / detector.total_detected) * 100
        print(f"–ù–∞—Ä–∏–π–≤—á–ª–∞–ª: {accuracy:.1f}%")
    print(f"\nüíæ –§–∞–π–ª—É—É–¥ —Ö–∞–¥–≥–∞–ª–∞–≥–¥—Å–∞–Ω: {detector.save_folder}/")
    print("\nüëã –ë–∞—è—Ä—Ç–∞–π!")
    print("="*70 + "\n")

if __name__ == "__main__":
    main()