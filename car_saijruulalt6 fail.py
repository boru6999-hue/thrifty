import cv2
import numpy as np
import pytesseract
from datetime import datetime
import os
from collections import deque
import tkinter as tk
from tkinter import filedialog

# Tesseract –∑–∞–º
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

class FastPlateDetector:
    def __init__(self):
        self.save_folder = "detected_plates"
        if not os.path.exists(self.save_folder):
            os.makedirs(self.save_folder)
        
        self.cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_russian_plate_number.xml'
        )
        
        self.detected_plates = []
        
        # –•–ê–¢–£–£ –¥–∞–≤—Ö—Ü–∞–ª —Ö—è–Ω–∞–ª—Ç
        self.detected_texts = set()  # –ù—ç–≥ —É–¥–∞–∞ –ª —Ç–∞–Ω–∏—Ö
        
        print("‚úÖ –•—É—Ä–¥–∞–Ω —Å–∏—Å—Ç–µ–º –±—ç–ª—ç–Ω!")
    
    def select_video(self):
        root = tk.Tk()
        root.withdraw()
        video_path = filedialog.askopenfilename(
            title="–í–∏–¥–µ–æ —Å–æ–Ω–≥–æ—Ö",
            filetypes=[
                ("Video files", "*.mp4 *.avi *.mov *.mkv *.flv *.wmv"),
                ("All files", "*.*")
            ]
        )
        root.destroy()
        return video_path
    
    def is_valid_plate(self, text):
        """–î—É–≥–∞–∞—Ä—ã–Ω —Ñ–æ—Ä–º–∞—Ç —à–∞–ª–≥–∞—Ö - –•–ê–¢–£–£"""
        if not text or len(text) < 5 or len(text) > 10:
            return False
        
        # –ó–ê–ê–í–ê–õ —Ç–æ–æ –±–∞–π—Ö —ë—Å—Ç–æ–π (2+)
        digit_count = sum(c.isdigit() for c in text)
        if digit_count < 2:
            return False
        
        # –ó–ê–ê–í–ê–õ “Ø—Å—ç–≥ –±–∞–π—Ö —ë—Å—Ç–æ–π
        letter_count = sum(c.isalpha() for c in text)
        if letter_count < 1:
            return False
        
        # –ó”©–≤—Ö”©–Ω “Ø—Å—ç–≥ —Ç–æ–æ
        if not text.isalnum():
            return False
        
        # –≠—Ö–Ω–∏–π —Ç—ç–º–¥—ç–≥—Ç —Ç–æ–æ –ë–òÿ¥ –±–∞–π—Ö (–∏—Ö—ç–Ω—Ö –¥—É–≥–∞–∞—Ä “Ø—Å—ç–≥—ç—ç—Ä —ç—Ö—ç–ª–Ω—ç)
        # –ñ–∏—à—ç—ç: –£–ë1234 ‚úì, 1234–£–ë ‚úó
        if text[0].isdigit():
            # –•—ç—Ä—ç–≤ —ç—Ö–ª—ç—ç–¥ —Ç–æ–æ –±–∞–π–≤–∞–ª, —è–¥–∞–∂ 3 “Ø—Å—ç–≥ –¥–∞—Ä–∞–∞ –Ω—å –±–∞–π—Ö —ë—Å—Ç–æ–π
            if letter_count < 3:
                return False
        
        return True
    
    def detect_plates(self, frame):
        """–•–£–†–î–ê–ù –∏–ª—Ä“Ø“Ø–ª—ç–ª—Ç"""
        # –ë–∞–≥–∞—Å–≥–∞–∞–¥ –∏–ª—Ä“Ø“Ø–ª—ç—Ö (—Ö—É—Ä–¥–∞–Ω)
        small = cv2.resize(frame, (640, 360))
        gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
        
        plates = self.cascade.detectMultiScale(
            gray, 
            scaleFactor=1.1,
            minNeighbors=3,
            minSize=(40, 15)
        )
        
        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã–≥ —ç—Ö —Ö—ç–º–∂—ç—ç–Ω–¥ –±—É—Ü–∞–∞—Ö
        scale_x = frame.shape[1] / 640
        scale_y = frame.shape[0] / 360
        
        scaled_plates = []
        for (x, y, w, h) in plates:
            x = int(x * scale_x)
            y = int(y * scale_y)
            w = int(w * scale_x)
            h = int(h * scale_y)
            
            # –•–∞—Ä—å—Ü–∞–∞ —à–∞–ª–≥–∞—Ö
            ratio = w / h
            if 2.0 <= ratio <= 5.5:
                scaled_plates.append((x, y, w, h))
        
        return scaled_plates
    
    def enhance_plate_fast(self, plate_img):
        """–•–£–†–î–ê–ù –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞–ª—Ç"""
        if len(plate_img.shape) == 3:
            gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)
        else:
            gray = plate_img.copy()
        
        h, w = gray.shape
        
        # –¢–æ–º—Ä—É—É–ª–∞—Ö - –ë–ê–ì–ê–ê–† (—Ö—É—Ä–¥–∞–Ω)
        target_h = 120  # –ë–∞–≥–∞—Å–≥–∞—Å–∞–Ω
        scale = target_h / h
        new_w = int(w * scale)
        gray = cv2.resize(gray, (new_w, target_h), interpolation=cv2.INTER_LINEAR)
        
        # –≠–Ω–≥–∏–π–Ω denoise
        gray = cv2.GaussianBlur(gray, (3, 3), 0)
        
        # CLAHE
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        gray = clahe.apply(gray)
        
        # 2 —Ç”©—Ä–ª–∏–π–Ω threshold
        _, binary1 = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        binary2 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                        cv2.THRESH_BINARY, 11, 2)
        
        return [binary1, binary2]
    
    def ocr_robust(self, images):
        """“Æ–† –î“Æ–ù–¢–≠–ô OCR - –ú–æ–Ω–≥–æ–ª –¥—É–≥–∞–∞—Ä—Ç —Ç–æ—Ö–∏—Ä—Å–æ–Ω"""
        all_results = []
        
        # –ú–æ–Ω–≥–æ–ª –±–æ–ª–æ–Ω –∞–Ω–≥–ª–∏ “Ø—Å—ç–≥
        whitelist = '0123456789–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø'
        
        # –û–ª–æ–Ω config —Ç—É—Ä—à–∏–Ω–∞
        configs = [
            f'--oem 3 --psm 7 -c tessedit_char_whitelist={whitelist}',
            f'--oem 3 --psm 8 -c tessedit_char_whitelist={whitelist}',
            f'--oem 1 --psm 7 -c tessedit_char_whitelist={whitelist}',
        ]
        
        for img in images:
            for config in configs:
                try:
                    # OCR data –∞–≤–∞—Ö (confidence-—Ç–∞–π)
                    data = pytesseract.image_to_data(img, config=config, 
                                                     output_type=pytesseract.Output.DICT)
                    
                    # –ò—Ç–≥—ç–ª—Ç—ç–π —Ç–µ–∫—Å—Ç“Ø“Ø–¥ –∞–≤–∞—Ö
                    texts = []
                    confs = []
                    
                    for i in range(len(data['text'])):
                        conf = int(data['conf'][i])
                        text = data['text'][i].strip()
                        
                        if conf > 50 and len(text) > 0:  # 50%+ –∏—Ç–≥—ç–ª
                            cleaned = self.clean_text(text)
                            if cleaned and len(cleaned) >= 2:
                                texts.append(cleaned)
                                confs.append(conf)
                    
                    # –ù—ç–≥—Ç–≥—ç—Ö
                    if texts:
                        full_text = ''.join(texts)
                        avg_conf = sum(confs) / len(confs)
                        
                        if self.is_valid_plate(full_text):
                            all_results.append((full_text, avg_conf))
                
                except:
                    pass
        
        # –•–∞–º–≥–∏–π–Ω —Å–∞–π–Ω “Ø—Ä –¥“Ø–Ω
        if all_results:
            # Confidence-–∞–∞—Ä —ç—Ä—ç–º–±—ç–ª—ç—Ö
            all_results.sort(key=lambda x: x[1], reverse=True)
            
            # –•–∞–º–≥–∏–π–Ω ”©–Ω–¥”©—Ä confidence
            best_text, best_conf = all_results[0]
            
            # –®–∞–ª–≥—É—É—Ä: 65%+ –±–∞–π—Ö —ë—Å—Ç–æ–π
            if best_conf >= 65:
                return best_text, best_conf
        
        return None, 0
    
    def clean_text(self, text):
        """–¢–µ–∫—Å—Ç —Ü—ç–≤—ç—Ä–ª—ç—Ö + –∑–∞—Å–≤–∞—Ä–ª–∞—Ö"""
        # –ó”©–≤—Ö”©–Ω “Ø—Å—ç–≥ —Ç–æ–æ
        cleaned = ''.join(c for c in text if c.isalnum())
        cleaned = cleaned.upper().strip()
        
        # –¢“Ø–≥—ç—ç–º—ç–ª –∞–ª–¥–∞–∞ –∑–∞—Å–∞—Ö
        replacements = {
            'O': '0',  # O -> 0
            'I': '1',  # I -> 1
            'Z': '2',  # Z -> 2
            'S': '5',  # S -> 5
            'B': '8',  # B -> 8
            'G': '6',  # G -> 6 (—Ç–∞–Ω–∞–π –∞—Å—É—É–¥–∞–ª!)
            'D': '0',  # D -> 0
            'Q': '0',  # Q -> 0
        }
        
        # –ó”©–≤—Ö”©–Ω —Ç–æ–æ –±–∞–π—Ö —ë—Å—Ç–æ–π —Ö—ç—Å—ç–≥—Ç –∑–∞—Å–≤–∞—Ä–ª–∞—Ö
        # –ú–æ–Ω–≥–æ–ª –¥—É–≥–∞–∞—Ä: –æ–±—ã—á–Ω–æ 2-4 “Ø—Å—ç–≥ + 4 —Ç–æ–æ
        result = []
        for i, char in enumerate(cleaned):
            # –•—ç—Ä—ç–≤ 3+ –¥–∞—Ö—å —Ç—ç–º–¥—ç–≥—Ç –±–æ–ª —Ç–æ–æ –±–∞–π—Ö –º–∞–≥–∞–¥–ª–∞–ª ”©–Ω–¥”©—Ä
            if i >= 3 and char in replacements:
                result.append(replacements[char])
            else:
                result.append(char)
        
        cleaned = ''.join(result)
        
        if len(cleaned) < 5 or len(cleaned) > 10:
            return None
        
        return cleaned
    
    def format_video_time(self, frame_number, fps):
        """–í–∏–¥–µ–æ–Ω—ã —Ü–∞–≥ —Ñ–æ—Ä–º–∞—Ç"""
        total_seconds = int(frame_number / fps)
        minutes = total_seconds // 60
        seconds = total_seconds % 60
        return f"{minutes:02d}:{seconds:02d}"
    
    def draw_table(self, frame, fps, current_frame):
        """–•“Ø—Å–Ω—ç–≥—Ç"""
        h, w = frame.shape[:2]
        table_w = 400
        table_x = w - table_w
        
        # –î—ç–≤—Å–≥—ç—Ä
        cv2.rectangle(frame, (table_x, 0), (w, h), (15, 15, 15), -1)
        
        # –ì–∞—Ä—á–∏–≥
        cv2.rectangle(frame, (table_x, 0), (w, 60), (0, 120, 0), -1)
        cv2.putText(frame, "TANISAN DUGAARUD", 
                   (table_x + 60, 40), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255), 2)
        
        # –¢–æ–ª–≥–æ–π
        y = 80
        cv2.line(frame, (table_x + 10, y), (w - 10, y), (80, 80, 80), 2)
        y += 30
        
        cv2.putText(frame, "#", (table_x + 15, y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        cv2.putText(frame, "Tsag", (table_x + 50, y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        cv2.putText(frame, "Dugaar", (table_x + 140, y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        cv2.putText(frame, "%", (table_x + 320, y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        
        y += 10
        cv2.line(frame, (table_x + 10, y), (w - 10, y), (80, 80, 80), 1)
        
        # –ú”©—Ä“Ø“Ø–¥
        for i, det in enumerate(self.detected_plates[-9:], 1):
            y += 40
            if y > h - 100:
                break
            
            video_time = det['video_time']
            plate = det['plate']
            conf = det['confidence']
            
            color = (0, 255, 0) if conf >= 80 else (0, 220, 220)
            
            cv2.putText(frame, f"{len(self.detected_plates) - 9 + i}", 
                       (table_x + 15, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
            
            cv2.putText(frame, video_time, (table_x + 50, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
            
            cv2.putText(frame, plate, (table_x + 140, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            
            cv2.putText(frame, f"{conf:.0f}", (table_x + 320, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫
        cv2.rectangle(frame, (table_x, h-70), (w, h), (25, 25, 25), -1)
        
        cv2.putText(frame, f"Niit olson: {len(self.detected_plates)}", 
                   (table_x + 15, h - 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 100), 2)
        
        if self.detected_plates:
            avg = sum(d['confidence'] for d in self.detected_plates) / len(self.detected_plates)
            cv2.putText(frame, f"Dundaj: {avg:.1f}%", 
                       (table_x + 15, h - 12), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 200, 255), 1)
        
        # –û–¥–æ–æ–≥–∏–π–Ω –≤–∏–¥–µ–æ —Ü–∞–≥
        current_time = self.format_video_time(current_frame, fps)
        cv2.putText(frame, f"Video: {current_time}", 
                   (table_x + 250, h - 12), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        
        return frame
    
    def draw_detection(self, frame, x, y, w, h, text, conf):
        """–î—É–≥–∞–∞—Ä –¥—ç—ç—Ä —Ö“Ø—Ä—ç—ç"""
        color = (0, 255, 0) if conf >= 80 else (0, 220, 220)
        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 3)
        
        if text:
            # –î—ç–≤—Å–≥—ç—Ä
            label = f"{text}"
            text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_DUPLEX, 0.8, 2)[0]
            
            cv2.rectangle(frame, (x, y-35), (x + text_size[0] + 15, y), (0, 0, 0), -1)
            cv2.rectangle(frame, (x, y-35), (x + text_size[0] + 15, y), color, 2)
            
            cv2.putText(frame, label, (x + 7, y - 10), 
                       cv2.FONT_HERSHEY_DUPLEX, 0.8, color, 2)
        
        return frame
    
    def create_result_window(self, plate_img, text, conf, video_time):
        """“Æ—Ä –¥“Ø–Ω —Ü–æ–Ω—Ö"""
        h, w = plate_img.shape[:2]
        scale = 180 / h
        enlarged = cv2.resize(plate_img, (int(w*scale), 180))
        
        window_h = 320
        window_w = max(enlarged.shape[1] + 40, 450)
        window = np.zeros((window_h, window_w, 3), dtype=np.uint8)
        window[:] = (20, 20, 20)
        
        # –ì–∞—Ä—á–∏–≥
        cv2.rectangle(window, (0, 0), (window_w, 50), (0, 100, 200), -1)
        cv2.putText(window, "TANISAN DUGAAR", 
                   (window_w//2 - 130, 35), cv2.FONT_HERSHEY_DUPLEX, 1.1, (255, 255, 255), 2)
        
        # –ó—É—Ä–∞–≥
        x_off = (window_w - enlarged.shape[1]) // 2
        window[60:240, x_off:x_off+enlarged.shape[1]] = enlarged
        
        # –î—É–≥–∞–∞—Ä - –¢–û–ú
        color = (0, 255, 0) if conf >= 80 else (0, 220, 220)
        cv2.putText(window, text, (20, 280), 
                   cv2.FONT_HERSHEY_DUPLEX, 1.8, color, 3)
        
        # –ú—ç–¥—ç—ç–ª—ç–ª
        info = f"{conf:.0f}% | Video: {video_time}"
        cv2.putText(window, info, (20, 310), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 1)
        
        return window
    
    def save_result(self, plate_img, text, conf, video_time):
        """–•–∞–¥–≥–∞–ª–∞—Ö"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –ó—É—Ä–∞–≥
        img_file = os.path.join(self.save_folder, f"{text}_{video_time.replace(':', '-')}_{timestamp}.jpg")
        cv2.imwrite(img_file, plate_img)
        
        # –¢–µ–∫—Å—Ç
        txt_file = os.path.join(self.save_folder, f"log.txt")
        with open(txt_file, 'a', encoding='utf-8') as f:
            f.write(f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | Video: {video_time} | {text} | {conf:.1f}%\n")

def main():
    print("\n" + "="*70)
    print(" "*10 + "üöó –í–ò–î–ï–û –î–£–ì–ê–ê–† –¢–ê–ù–ò–• (–≠–¶–°–ò–ô–ù –•–£–í–ò–õ–ë–ê–†) üöó")
    print("="*70)
    print("\n‚ö° –û–Ω—Ü–ª–æ–≥:")
    print("  ‚Ä¢ –•–£–†–î–ê–ù (–±–∞–≥–∞—Å–≥–∞–∞–¥ –∏–ª—Ä“Ø“Ø–ª–Ω—ç)")
    print("  ‚Ä¢ –ù–≠–ì —É–¥–∞–∞ –ª —Ç–∞–Ω–∏—Ö (–¥–∞–≤—Ö—Ü–∞—Ö–≥“Ø–π)")
    print("  ‚Ä¢ –í–∏–¥–µ–æ–Ω—ã —Ü–∞–≥ —Ö–∞—Ä—É—É–ª–Ω–∞ (00:15)")
    print("  ‚Ä¢ –ê–ª–¥–∞–∞ –∑–∞—Å–Ω–∞ (G‚Üí6, O‚Üí0, I‚Üí1)")
    print("  ‚Ä¢ –ú–æ–Ω–≥–æ–ª –¥—É–≥–∞–∞—Ä –¥—ç–º–∂–∏–Ω—ç")
    print("\n" + "-"*70 + "\n")
    
    detector = FastPlateDetector()
    
    print("üìÅ –í–∏–¥–µ–æ —Å–æ–Ω–≥–æ—Ö...")
    video_path = detector.select_video()
    
    if not video_path:
        print("‚ùå –í–∏–¥–µ–æ —Å–æ–Ω–≥–æ–≥–¥—Å–æ–Ω–≥“Ø–π!")
        return
    
    print(f"‚úÖ –í–∏–¥–µ–æ: {os.path.basename(video_path)}\n")
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("‚ùå –í–∏–¥–µ–æ –Ω—ç—ç–≥–¥—Å—ç–Ω–≥“Ø–π!")
        return
    
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    duration = total_frames / fps
    
    print(f"üìä –ú—ç–¥—ç—ç–ª—ç–ª:")
    print(f"   Resolution: {width}x{height}")
    print(f"   FPS: {fps}")
    print(f"   Duration: {int(duration//60)}:{int(duration%60):02d}")
    print(f"   Frames: {total_frames}\n")
    
    # Display size
    display_w = 1280 if width > 1280 else width
    display_h = int(height * (display_w / width))
    
    print("üöÄ –≠—Ö—ç–ª–∂ –±–∞–π–Ω–∞...\n")
    print("   SPACE - –ó–æ–≥—Å–æ–æ—Ö/“Æ—Ä–≥—ç–ª–∂–ª“Ø“Ø–ª—ç—Ö")
    print("   Q - –î—É—É—Å–≥–∞—Ö\n")
    print("-"*70 + "\n")
    
    frame_count = 0
    paused = False
    
    # FPS —Ö–∞—Ä—É—É–ª–∞—Ö
    prev_time = cv2.getTickCount()
    fps_display = 0
    
    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                print("\n‚úÖ –í–∏–¥–µ–æ –¥—É—É—Å–ª–∞–∞!")
                break
            
            frame_count += 1
            
            # Resize
            if frame.shape[1] != display_w:
                frame = cv2.resize(frame, (display_w, display_h))
            
            # FPS
            curr_time = cv2.getTickCount()
            time_diff = (curr_time - prev_time) / cv2.getTickFrequency()
            if time_diff > 0:
                fps_display = 1.0 / time_diff
            prev_time = curr_time
            
            # 8 frame —Ç—É—Ç–∞–º–¥ —Ç–∞–Ω–∏—Ö (–•–£–†–î–ê–ù)
            if frame_count % 8 == 0:
                plates = detector.detect_plates(frame)
                
                for (x, y, w, h) in plates:
                    plate_img = frame[y:y+h, x:x+w]
                    
                    # –ë–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö
                    enhanced = detector.enhance_plate_fast(plate_img)
                    
                    # OCR
                    text, conf = detector.ocr_robust(enhanced)
                    
                    # –®–∞–ª–≥–∞—Ö: ”©–Ω–¥”©—Ä –∏—Ç–≥—ç–ª + –î–ê–í–•–¶–ê–ê–ì“Æ–ô
                    if text and conf >= 65:
                        if text not in detector.detected_texts:
                            # –ù–≠–ì —É–¥–∞–∞ –ª —Ç–∞–Ω–∏—Ö!
                            detector.detected_texts.add(text)
                            
                            video_time = detector.format_video_time(frame_count, fps)
                            
                            detector.detected_plates.append({
                                'video_time': video_time,
                                'plate': text,
                                'confidence': conf
                            })
                            
                            detector.save_result(plate_img, text, conf, video_time)
                            
                            print(f"‚úÖ {len(detector.detected_plates)}. {text} ({conf:.0f}%) - {video_time}")
                            
                            # “Æ—Ä –¥“Ø–Ω —Ü–æ–Ω—Ö
                            result_win = detector.create_result_window(
                                plate_img, text, conf, video_time
                            )
                            cv2.imshow(f"{text} - {video_time}", result_win)
                    
                    # –ó—É—Ä–∞—Ö
                    if text and conf >= 65:
                        frame = detector.draw_detection(frame, x, y, w, h, text, conf)
            
            # –•“Ø—Å–Ω—ç–≥—Ç
            frame = detector.draw_table(frame, fps, frame_count)
            
            # –°—Ç–∞—Ç—É—Å
            h_frame = frame.shape[0]
            cv2.rectangle(frame, (5, h_frame-60), (350, h_frame-5), (25, 25, 25), -1)
            
            cv2.putText(frame, f"FPS: {fps_display:.1f}", (10, h_frame-35), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 100), 2)
            
            progress = (frame_count / total_frames) * 100
            cv2.putText(frame, f"Progress: {progress:.1f}%", (10, h_frame-12), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (100, 200, 255), 2)
        
        cv2.imshow('Video Plate Detection - Final', frame)
        
        key = cv2.waitKey(1) & 0xFF
        
        if key == ord('q') or key == ord('Q'):
            print("\nüõë –ó–æ–≥—Å–æ–æ—Å–æ–Ω")
            break
        elif key == ord(' '):
            paused = not paused
            print("‚è∏Ô∏è  –ó–û–ì–°–û–û–°–û–ù" if paused else "‚ñ∂Ô∏è  “Æ–†–ì–≠–õ–ñ–ò–õ–ñ –ë–ê–ô–ù–ê")
    
    cap.release()
    cv2.destroyAllWindows()
    
    # –¢–∞–π–ª–∞–Ω
    print("\n" + "="*70)
    print(" "*25 + "üìä –î“Æ–ì–ù–≠–õ–¢")
    print("="*70)
    print(f"–¢–∞–Ω–∏–≥–¥—Å–∞–Ω –¥—É–≥–∞–∞—Ä: {len(detector.detected_plates)}")
    
    if detector.detected_plates:
        print(f"\nüìã –ë“Ø—Ö –¥—É–≥–∞–∞—Ä—É—É–¥:")
        for i, det in enumerate(detector.detected_plates, 1):
            print(f"  {i}. {det['plate']} ({det['confidence']:.0f}%) - Video: {det['video_time']}")
        
        avg = sum(d['confidence'] for d in detector.detected_plates) / len(detector.detected_plates)
        print(f"\n–î—É–Ω–¥–∞–∂ confidence: {avg:.1f}%")
    
    print(f"\nüíæ –•–∞–¥–≥–∞–ª–∞–≥–¥—Å–∞–Ω: {detector.save_folder}/")
    print("   - –ó—É—Ä–≥—É—É–¥")
    print("   - log.txt —Ñ–∞–π–ª")
    print("\nüëã –ë–∞—è—Ä—Ç–∞–π!")
    print("="*70 + "\n")

if __name__ == "__main__":
    main()