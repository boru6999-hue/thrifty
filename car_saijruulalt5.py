import cv2
import numpy as np
import pytesseract
from datetime import datetime
import os
from collections import deque
import tkinter as tk
from tkinter import filedialog
import re

# Tesseract –∑–∞–º
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

class StrictPlateDetector:
    def __init__(self):
        # –•–∞–≤—Ç–∞—Å “Ø“Ø—Å–≥—ç—Ö
        self.save_folder = "detected_plates"
        if not os.path.exists(self.save_folder):
            os.makedirs(self.save_folder)
        
        # Classifier
        self.cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_russian_plate_number.xml'
        )
        
        # –•“Ø—Å–Ω—ç–≥—Ç –º—ç–¥—ç—ç–ª—ç–ª
        self.detected_plates = []
        
        # –°“Ø“Ø–ª–∏–π–Ω –¥—É–≥–∞–∞—Ä—É—É–¥ (–¥–∞–≤—Ö—Ü–∞—Ö “Ø–µ–¥ –∞–ª–≥–∞—Å–∞—Ö)
        self.recent_plates = {}  # {text: last_frame_number}
        
        # –•–ê–¢–£–£ –®–ê–õ–ì–£–£–†
        self.MIN_CONFIDENCE = 75  # –î–æ–æ–¥ –∏—Ç–≥—ç–ª 75%
        self.MIN_PLATE_SIZE = 80   # –î—É–≥–∞–∞—Ä—ã–Ω –¥–æ–æ–¥ —Ö—ç–º–∂—ç—ç (pixel)
        self.FRAME_SKIP = 30       # 30 frame –∞–ª–≥–∞—Å–∞—Ö (–¥–∞–≤—Ö—Ü–∞—Ö “Ø–µ–¥)
        
        print("‚úÖ –•–∞—Ç—É—É —à–∞–ª–≥—É—É—Ä—ã–Ω —Å–∏—Å—Ç–µ–º –±—ç–ª—ç–Ω!")
    
    def select_video(self):
        """–í–∏–¥–µ–æ —Å–æ–Ω–≥–æ—Ö"""
        root = tk.Tk()
        root.withdraw()
        video_path = filedialog.askopenfilename(
            title="–í–∏–¥–µ–æ —Å–æ–Ω–≥–æ—Ö",
            filetypes=[
                ("Video files", "*.mp4 *.avi *.mov *.mkv"),
                ("All files", "*.*")
            ]
        )
        root.destroy()
        return video_path
    
    def is_valid_plate_format(self, text):
        """–î—É–≥–∞–∞—Ä—ã–Ω —Ñ–æ—Ä–º–∞—Ç –∑”©–≤ —ç—Å—ç—Ö–∏–π–≥ —à–∞–ª–≥–∞—Ö"""
        if not text or len(text) < 5 or len(text) > 10:
            return False
        
        # –•–∞–º–≥–∏–π–Ω –±–∞–≥–∞–¥–∞–∞ 2 —Ç–æ–æ, 2 “Ø—Å—ç–≥ –±–∞–π—Ö —ë—Å—Ç–æ–π
        digit_count = sum(c.isdigit() for c in text)
        letter_count = sum(c.isalpha() for c in text)
        
        if digit_count < 2 or letter_count < 1:
            return False
        
        # –ó”©–≤—Ö”©–Ω “Ø—Å—ç–≥ —Ç–æ–æ –±–∞–π—Ö
        if not text.isalnum():
            return False
        
        # –ú–æ–Ω–≥–æ–ª –¥—É–≥–∞–∞—Ä—ã–Ω pattern (–∂–∏—à—ç—ç: –£–ë1234–ê–ê, 1234–£–ë–ê –≥—ç—Ö –º—ç—Ç)
        # –≠–Ω—ç —Ö—ç—Å–≥–∏–π–≥ ”©”©—Ä–∏–π–Ω —É–ª—Å—ã–Ω –¥—É–≥–∞–∞—Ä—ã–Ω format-–¥ —Ç–æ—Ö–∏—Ä—É—É–ª–∂ –±–æ–ª–Ω–æ
        
        return True
    
    def is_duplicate(self, text, frame_number):
        """–î–∞–≤—Ö—Ü—Å–∞–Ω —ç—Å—ç—Ö–∏–π–≥ frame number-–∞–∞—Ä —à–∞–ª–≥–∞—Ö"""
        if text in self.recent_plates:
            last_frame = self.recent_plates[text]
            if frame_number - last_frame < self.FRAME_SKIP:
                return True
        
        self.recent_plates[text] = frame_number
        return False
    
    def detect_plates(self, frame):
        """–î—É–≥–∞–∞—Ä –∏–ª—Ä“Ø“Ø–ª—ç—Ö - –∑”©–≤—Ö”©–Ω —Ç–æ–º, —Ç–æ–¥–æ—Ä—Ö–æ–π –¥—É–≥–∞–∞—Ä—ã–≥"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # Contrast —Å–∞–π–∂—Ä—É—É–ª–∞—Ö
        gray = cv2.equalizeHist(gray)
        
        # –ò–ª—Ä“Ø“Ø–ª—ç—Ö - –•–ê–¢–£–£ –ø–∞—Ä–∞–º–µ—Ç—Ä
        plates = self.cascade.detectMultiScale(
            gray, 
            scaleFactor=1.08,      # –ë–∞–≥–∞ scale = –±–∞–≥–∞ –¥—É–≥–∞–∞—Ä
            minNeighbors=5,        # –ò–ª“Ø“Ø –∏—Ç–≥—ç–ª—Ç—ç–π
            minSize=(self.MIN_PLATE_SIZE, 30),  # –î–æ–æ–¥ —Ö—ç–º–∂—ç—ç
            maxSize=(500, 200)
        )
        
        # –î—É–≥–∞–∞—Ä—ã–Ω —Ö–∞—Ä—å—Ü–∞–∞–≥ —à–∞–ª–≥–∞—Ö (”©—Ä–≥”©–Ω/”©–Ω–¥”©—Ä = 2-5 –æ—Ä—á–∏–º)
        valid_plates = []
        for (x, y, w, h) in plates:
            aspect_ratio = w / h
            if 2.0 <= aspect_ratio <= 5.5:  # –î—É–≥–∞–∞—Ä—ã–Ω —Ö—ç–≤–∏–π–Ω —Ö–∞—Ä—å—Ü–∞–∞
                valid_plates.append((x, y, w, h))
        
        return valid_plates
    
    def preprocess_plate(self, plate_img):
        """–•–ê–ú–ì–ò–ô–ù —Å–∞–π–Ω –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞–ª—Ç"""
        if len(plate_img.shape) == 3:
            gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)
        else:
            gray = plate_img.copy()
        
        h, w = gray.shape
        
        # 1. –ê–°–ê–† –¢–û–ú –±–æ–ª–≥–æ—Ö (300px ”©–Ω–¥”©—Ä)
        scale = 300 / h
        new_w = int(w * scale)
        gray = cv2.resize(gray, (new_w, 300), interpolation=cv2.INTER_LANCZOS4)
        
        # 2. Bilateral filter (–∫—Ä–∞—è —Ö–∞–¥–≥–∞–ª–∂ noise –∞—Ä–∏–ª–≥–∞—Ö)
        gray = cv2.bilateralFilter(gray, 11, 17, 17)
        
        # 3. CLAHE - —Ö“Ø—á—Ç—ç–π contrast
        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8,8))
        gray = clahe.apply(gray)
        
        # 4. Unsharp masking (—Ç–æ–¥ –±–æ–ª–≥–æ—Ö)
        gaussian = cv2.GaussianBlur(gray, (0, 0), 2.0)
        gray = cv2.addWeighted(gray, 2.0, gaussian, -1.0, 0)
        
        # 5. –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        gray = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)
        gray = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)
        
        # 6. Adaptive threshold
        binary = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY, 15, 2
        )
        
        # 7. –≠—Ü—Å–∏–π–Ω denoise
        binary = cv2.medianBlur(binary, 3)
        
        return binary, gray
    
    def recognize_text_strict(self, plate_img):
        """–ú–ê–ê–®–ì“Æ–ô –•–ê–¢–£–£ OCR"""
        try:
            # –ë–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö
            binary, gray = self.preprocess_plate(plate_img)
            
            # Tesseract config - –∑”©–≤—Ö”©–Ω “Ø—Å—ç–≥ —Ç–æ–æ
            configs = [
                '--oem 3 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è',
                '--oem 1 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è',
                '--oem 3 --psm 8 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è',
            ]
            
            all_results = []
            
            # –û–ª–æ–Ω –∞—Ä–≥–∞–∞—Ä —Ç—É—Ä—à–∏–Ω–∞
            test_images = [
                binary,
                cv2.bitwise_not(binary),  # –£—Ä–≤—É—É
                gray,  # –°–∞–∞—Ä–∞–ª
            ]
            
            for img in test_images:
                for config in configs:
                    try:
                        # OCR —Ö–∏–π—Ö
                        data = pytesseract.image_to_data(img, config=config, output_type=pytesseract.Output.DICT)
                        
                        # –ò—Ç–≥—ç–ª—Ç—ç–π —Ç–µ–∫—Å—Ç –∞–≤–∞—Ö
                        texts = []
                        confidences = []
                        
                        for i in range(len(data['text'])):
                            conf = int(data['conf'][i])
                            text = data['text'][i].strip()
                            
                            if conf > 60 and text:  # 60%-–∞–∞—Å –¥—ç—ç—à –∏—Ç–≥—ç–ª
                                cleaned = self.clean_text(text)
                                if cleaned:
                                    texts.append(cleaned)
                                    confidences.append(conf)
                        
                        # –ë“Ø—Ö —Ç–µ–∫—Å—Ç–∏–π–≥ –Ω—ç–≥—Ç–≥—ç—Ö
                        if texts:
                            full_text = ''.join(texts)
                            avg_conf = sum(confidences) / len(confidences)
                            
                            if self.is_valid_plate_format(full_text):
                                all_results.append((full_text, avg_conf))
                    
                    except:
                        pass
            
            # –•–∞–º–≥–∏–π–Ω —Å–∞–π–Ω “Ø—Ä –¥“Ø–Ω —Å–æ–Ω–≥–æ—Ö
            if all_results:
                # –ò—Ç–≥—ç–ª –±–∞ –¥–∞–≤—Ç–∞–º–∂–∞–∞—Ä —ç—Ä—ç–º–±—ç–ª—ç—Ö
                from collections import Counter
                
                # –¢–µ–∫—Å—Ç“Ø“Ø–¥–∏–π–≥ —Ç–æ–æ–ª–æ—Ö
                text_counts = Counter([r[0] for r in all_results])
                
                # –•–∞–º–≥–∏–π–Ω –∏—Ö –¥–∞–≤—Ç–∞–≥–¥—Å–∞–Ω, ”©–Ω–¥”©—Ä –∏—Ç–≥—ç–ª—Ç—ç–π —Ç–µ–∫—Å—Ç
                best_candidates = []
                for text, count in text_counts.most_common(3):
                    # –≠–Ω—ç —Ç–µ–∫—Å—Ç–∏–π–Ω –¥—É–Ω–¥–∞–∂ –∏—Ç–≥—ç–ª
                    confs = [r[1] for r in all_results if r[0] == text]
                    avg_conf = sum(confs) / len(confs)
                    best_candidates.append((text, avg_conf, count))
                
                # –≠—Ä—ç–º–±—ç–ª—ç—Ö: –¥–∞–≤—Ç–∞–º–∂ * –∏—Ç–≥—ç–ª
                best_candidates.sort(key=lambda x: x[1] * x[2], reverse=True)
                
                if best_candidates:
                    best_text, best_conf, _ = best_candidates[0]
                    
                    # –•–ê–¢–£–£ —à–∞–ª–≥—É—É—Ä: 75%-–∞–∞—Å –¥—ç—ç—à –±–∞–π—Ö —ë—Å—Ç–æ–π
                    if best_conf >= self.MIN_CONFIDENCE:
                        return best_text, best_conf, binary
                    
        except Exception as e:
            print(f"   ‚ö†Ô∏è  OCR –∞–ª–¥–∞–∞: {e}")
        
        return None, 0, None
    
    def clean_text(self, text):
        """–¢–µ–∫—Å—Ç —Ü—ç–≤—ç—Ä–ª—ç—Ö - —Ö–∞—Ç—É—É"""
        # –ó”©–≤—Ö”©–Ω “Ø—Å—ç–≥ —Ç–æ–æ
        cleaned = ''.join(c for c in text if c.isalnum())
        cleaned = cleaned.upper().strip()
        
        # –ë–æ–≥–∏–Ω–æ —ç—Å–≤—ç–ª —É—Ä—Ç –±–æ–ª “Ø–≥“Ø–π
        if len(cleaned) < 5 or len(cleaned) > 10:
            return None
        
        return cleaned
    
    def create_enlarged_view(self, plate_img, processed_img, text, confidence):
        """–¢–æ–º —Ö–∞—Ä—É—É–ª–∞—Ö —Ü–æ–Ω—Ö - –≥–æ—ë"""
        # –ó—É—Ä–≥—É—É–¥—ã–≥ —Ç–æ–º—Ä—É—É–ª–∞—Ö
        h, w = plate_img.shape[:2]
        scale = 250 / h
        new_w = int(w * scale)
        
        enlarged_orig = cv2.resize(plate_img, (new_w, 250))
        
        if processed_img is not None:
            # Processed –∑—É—Ä–≥–∏–π–≥ RGB –±–æ–ª–≥–æ—Ö
            processed_rgb = cv2.cvtColor(processed_img, cv2.COLOR_GRAY2BGR)
            processed_rgb = cv2.resize(processed_rgb, (new_w, 250))
        else:
            processed_rgb = enlarged_orig.copy()
        
        # –¶–æ–Ω—Ö–Ω—ã —Ö—ç–º–∂—ç—ç
        window_h = 250 * 2 + 150  # 2 –∑—É—Ä–∞–≥ + –º—ç–¥—ç—ç–ª—ç–ª
        window_w = max(new_w, 500)
        
        # –•–∞—Ä –¥—ç–≤—Å–≥—ç—Ä
        window = np.zeros((window_h, window_w, 3), dtype=np.uint8)
        window[:] = (20, 20, 20)
        
        # –ì–∞—Ä—á–∏–≥
        cv2.rectangle(window, (0, 0), (window_w, 50), (0, 100, 200), -1)
        cv2.putText(window, "TANISAN DUGAAR", 
                   (window_w//2 - 120, 35), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255), 2)
        
        # –≠—Ö –∑—É—Ä–∞–≥
        y_pos = 60
        x_offset = (window_w - new_w) // 2
        window[y_pos:y_pos+250, x_offset:x_offset+new_w] = enlarged_orig
        cv2.putText(window, "Original", (x_offset + 10, y_pos + 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (100, 255, 100), 2)
        
        # –ë–æ–ª–æ–≤—Å—Ä—É—É–ª—Å–∞–Ω –∑—É—Ä–∞–≥
        y_pos += 260
        window[y_pos:y_pos+250, x_offset:x_offset+new_w] = processed_rgb
        cv2.putText(window, "Processed", (x_offset + 10, y_pos + 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (100, 255, 100), 2)
        
        # –ú—ç–¥—ç—ç–ª—ç–ª
        y_pos += 270
        
        # –î—É–≥–∞–∞—Ä - –¢–û–ú
        if text:
            color = (0, 255, 0) if confidence >= 85 else (0, 200, 255)
            cv2.putText(window, text, (20, y_pos), 
                       cv2.FONT_HERSHEY_DUPLEX, 2, color, 3)
            
            # –ò—Ç–≥—ç–ª
            conf_text = f"Confidence: {confidence:.1f}%"
            cv2.putText(window, conf_text, (20, y_pos + 50), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
            
            # –û–≥–Ω–æ–æ
            time_now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            cv2.putText(window, time_now, (20, y_pos + 90), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (150, 150, 150), 1)
        
        return window
    
    def draw_table(self, frame):
        """–•“Ø—Å–Ω—ç–≥—Ç –∑—É—Ä–∞—Ö"""
        h, w = frame.shape[:2]
        table_width = 380
        table_x = w - table_width
        
        # –î—ç–≤—Å–≥—ç—Ä
        overlay = frame.copy()
        cv2.rectangle(overlay, (table_x, 0), (w, h), (15, 15, 15), -1)
        cv2.addWeighted(overlay, 0.9, frame, 0.1, 0, frame)
        
        # –ì–∞—Ä—á–∏–≥
        cv2.rectangle(frame, (table_x, 0), (w, 60), (0, 120, 0), -1)
        cv2.putText(frame, "BURTGEL", 
                   (table_x + 120, 40), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255), 2)
        
        # –¢–æ–ª–≥–æ–π
        y = 75
        cv2.line(frame, (table_x + 10, y), (w - 10, y), (100, 100, 100), 2)
        y += 30
        
        cv2.putText(frame, "#", (table_x + 15, y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        cv2.putText(frame, "Tsag", (table_x + 50, y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        cv2.putText(frame, "Dugaar", (table_x + 140, y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        cv2.putText(frame, "Conf", (table_x + 290, y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        
        y += 5
        cv2.line(frame, (table_x + 10, y), (w - 10, y), (100, 100, 100), 1)
        
        # –ú”©—Ä“Ø“Ø–¥ (—Å“Ø“Ø–ª–∏–π–Ω 10)
        start_idx = max(0, len(self.detected_plates) - 10)
        for i, detection in enumerate(self.detected_plates[start_idx:], start=start_idx+1):
            y += 45
            if y > h - 100:
                break
            
            time_str = detection['time'].strftime("%H:%M:%S")
            plate = detection['plate']
            conf = detection['confidence']
            
            color = (0, 255, 0) if conf >= 85 else (0, 220, 220)
            
            # –î—É–≥–∞–∞—Ä
            cv2.putText(frame, f"{i}", (table_x + 15, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
            
            # –¶–∞–≥
            cv2.putText(frame, time_str, (table_x + 50, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.55, (200, 200, 200), 1)
            
            # –î—É–≥–∞–∞—Ä
            cv2.putText(frame, plate, (table_x + 140, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            
            # Confidence
            cv2.putText(frame, f"{conf:.0f}%", (table_x + 290, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫
        cv2.rectangle(frame, (table_x, h - 70), (w, h), (30, 30, 30), -1)
        cv2.putText(frame, f"Niit olson: {len(self.detected_plates)}", 
                   (table_x + 20, h - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 100), 2)
        
        if self.detected_plates:
            avg_conf = sum(d['confidence'] for d in self.detected_plates) / len(self.detected_plates)
            cv2.putText(frame, f"Dundaj confidence: {avg_conf:.1f}%", 
                       (table_x + 20, h - 12), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 200, 255), 1)
        
        return frame
    
    def save_detection(self, plate_img, processed_img, text, confidence):
        """–•–∞–¥–≥–∞–ª–∞—Ö"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        
        # –≠—Ö –∑—É—Ä–∞–≥
        img_file = os.path.join(self.save_folder, f"plate_{timestamp}.jpg")
        cv2.imwrite(img_file, plate_img)
        
        # –ë–æ–ª–æ–≤—Å—Ä—É—É–ª—Å–∞–Ω –∑—É—Ä–∞–≥
        if processed_img is not None:
            proc_file = os.path.join(self.save_folder, f"processed_{timestamp}.jpg")
            cv2.imwrite(proc_file, processed_img)
        
        # –¢–µ–∫—Å—Ç
        txt_file = os.path.join(self.save_folder, f"plate_{timestamp}.txt")
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(f"–û–≥–Ω–æ–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"–î—É–≥–∞–∞—Ä: {text}\n")
            f.write(f"–ò—Ç–≥—ç–ª: {confidence:.1f}%\n")

def main():
    print("\n" + "="*70)
    print(" "*12 + "üöó –í–ò–î–ï–û –î–£–ì–ê–ê–† –¢–ê–ù–ò–• (”®–ù–î”®–† –ù–ê–†–ò–ô–í–ß–õ–ê–õ) üöó")
    print("="*70)
    print("\n‚ö†Ô∏è  –•–ê–¢–£–£ –®–ê–õ–ì–£–£–†:")
    print(f"  ‚Ä¢ –î–æ–æ–¥ –∏—Ç–≥—ç–ª: 75%")
    print(f"  ‚Ä¢ –î–æ–æ–¥ —Ö—ç–º–∂—ç—ç: 80px")
    print(f"  ‚Ä¢ –ó”©–≤—Ö”©–Ω –∑”©–≤ —Ñ–æ—Ä–º–∞—Ç")
    print(f"  ‚Ä¢ –î–∞–≤—Ö—Ü–∞–ª: 30 frame")
    print("\n" + "-"*70 + "\n")
    
    detector = StrictPlateDetector()
    
    # –í–∏–¥–µ–æ —Å–æ–Ω–≥–æ—Ö
    print("üìÅ –í–∏–¥–µ–æ —Ñ–∞–π–ª —Å–æ–Ω–≥–æ–Ω–æ —É—É...")
    video_path = detector.select_video()
    
    if not video_path:
        print("‚ùå –í–∏–¥–µ–æ —Å–æ–Ω–≥–æ–≥–¥—Å–æ–Ω–≥“Ø–π!")
        return
    
    print(f"‚úÖ –í–∏–¥–µ–æ: {os.path.basename(video_path)}\n")
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("‚ùå –í–∏–¥–µ–æ –Ω—ç—ç–≥–¥—Å—ç–Ω–≥“Ø–π!")
        return
    
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"üé¨ FPS: {fps} | Frame: {total_frames} | “Æ—Ä–≥—ç–ª–∂–ª—ç—Ö: {total_frames/fps:.1f}s\n")
    print("üöÄ –≠—Ö–ª“Ø“Ø–ª–∂ –±–∞–π–Ω–∞...\n")
    print("   SPACE - –ó–æ–≥—Å–æ–æ—Ö/“Æ—Ä–≥—ç–ª–∂–ª“Ø“Ø–ª—ç—Ö")
    print("   Q - –î—É—É—Å–≥–∞—Ö\n")
    print("-"*70 + "\n")
    
    frame_count = 0
    paused = False
    detection_windows = {}
    
    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                print("\n‚úÖ –í–∏–¥–µ–æ –¥—É—É—Å–ª–∞–∞!")
                break
            
            frame_count += 1
            
            # Resolution
            h, w = frame.shape[:2]
            if w > 1280:
                scale = 1280 / w
                frame = cv2.resize(frame, (1280, int(h * scale)))
            
            # 2 frame —Ç—É—Ç–∞–º–¥ —Ç–∞–Ω–∏—Ö (–∏–ª“Ø“Ø –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª—Ç–∞–π)
            if frame_count % 2 == 0:
                plates = detector.detect_plates(frame)
                
                for (x, y, w_p, h_p) in plates:
                    plate_img = frame[y:y+h_p, x:x+w_p]
                    
                    # –•–ê–¢–£–£ OCR
                    text, confidence, processed = detector.recognize_text_strict(plate_img)
                    
                    # –ó”®–í–•”®–ù ”©–Ω–¥”©—Ä –∏—Ç–≥—ç–ª—Ç—ç–π, –¥–∞–≤—Ö—Ü–∞–∞–≥“Ø–π
                    if text and confidence >= detector.MIN_CONFIDENCE:
                        if not detector.is_duplicate(text, frame_count):
                            # –•–∞–¥–≥–∞–ª–∞—Ö
                            detector.detected_plates.append({
                                'time': datetime.now(),
                                'plate': text,
                                'confidence': confidence
                            })
                            
                            detector.save_detection(plate_img, processed, text, confidence)
                            
                            print(f"‚úÖ #{len(detector.detected_plates)}: {text} ({confidence:.1f}%)")
                            
                            # –¢–æ–º —Ö–∞—Ä—É—É–ª–∞—Ö —Ü–æ–Ω—Ö
                            enlarged = detector.create_enlarged_view(
                                plate_img, processed, text, confidence
                            )
                            window_name = f"Dugaar #{len(detector.detected_plates)} - {text}"
                            cv2.imshow(window_name, enlarged)
                            detection_windows[window_name] = True
                    
                    # –ó—É—Ä–∞—Ö (–∑”©–≤—Ö”©–Ω –±–æ–¥–∏—Ç –¥—É–≥–∞–∞—Ä—ã–≥)
                    if text and confidence >= detector.MIN_CONFIDENCE:
                        color = (0, 255, 0) if confidence >= 85 else (0, 200, 255)
                        cv2.rectangle(frame, (x, y), (x+w_p, y+h_p), color, 3)
                        
                        label = f"{text} ({confidence:.0f}%)"
                        cv2.rectangle(frame, (x, y-35), (x + 250, y), (0, 0, 0), -1)
                        cv2.rectangle(frame, (x, y-35), (x + 250, y), color, 2)
                        cv2.putText(frame, label, (x + 5, y - 10), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            
            # –•“Ø—Å–Ω—ç–≥—Ç
            frame = detector.draw_table(frame)
            
            # Progress
            progress = (frame_count / total_frames) * 100
            cv2.rectangle(frame, (5, frame.shape[0] - 35), (300, frame.shape[0] - 5), (40, 40, 40), -1)
            cv2.putText(frame, f"Progress: {progress:.1f}% | Frame: {frame_count}", 
                       (10, frame.shape[0] - 12), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (100, 200, 100), 2)
        
        cv2.imshow('Video Dugaar Tanikh - Strict Mode', frame)
        
        key = cv2.waitKey(1 if not paused else 0) & 0xFF
        if key == ord('q') or key == ord('Q'):
            break
        elif key == ord(' '):
            paused = not paused
            print("‚è∏Ô∏è  –ó–æ–≥—Å–æ–æ—Å–æ–Ω" if paused else "‚ñ∂Ô∏è  “Æ—Ä–≥—ç–ª–∂–∏–ª–∂ –±–∞–π–Ω–∞")
    
    cap.release()
    cv2.destroyAllWindows()
    
    # –î“Ø–≥–Ω—ç–ª—Ç
    print("\n" + "="*70)
    print(" "*25 + "üìä –î“Æ–ì–ù–≠–õ–¢")
    print("="*70)
    print(f"–ù–∏–π—Ç –ë–û–î–ò–¢ –¥—É–≥–∞–∞—Ä: {len(detector.detected_plates)}")
    
    if detector.detected_plates:
        avg_conf = sum(d['confidence'] for d in detector.detected_plates) / len(detector.detected_plates)
        print(f"–î—É–Ω–¥–∞–∂ –∏—Ç–≥—ç–ª: {avg_conf:.1f}%")
        
        print(f"\nüìã –ë“Ø—Ö –¥—É–≥–∞–∞—Ä—É—É–¥:")
        for i, det in enumerate(detector.detected_plates, 1):
            print(f"  {i}. {det['plate']} ({det['confidence']:.1f}%) - {det['time'].strftime('%H:%M:%S')}")
    
    print(f"\nüíæ –§–∞–π–ª—É—É–¥: {detector.save_folder}/")
    print("\nüëã –ë–∞—è—Ä—Ç–∞–π!")
    print("="*70 + "\n")

if __name__ == "__main__":
    main()