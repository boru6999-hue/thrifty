import cv2
import numpy as np
import pytesseract
from datetime import datetime
import os
from collections import deque
import tkinter as tk
from tkinter import filedialog
import re

# Tesseract –∑–∞–º
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

class VideoPlateDetector:
    def __init__(self):
        # –•–∞–≤—Ç–∞—Å “Ø“Ø—Å–≥—ç—Ö
        self.save_folder = "detected_plates"
        if not os.path.exists(self.save_folder):
            os.makedirs(self.save_folder)
        
        # –î—É–≥–∞–∞—Ä –∏–ª—Ä“Ø“Ø–ª—ç—Ö classifier
        self.cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_russian_plate_number.xml'
        )
        
        # –•“Ø—Å–Ω—ç–≥—Ç –º—ç–¥—ç—ç–ª—ç–ª
        self.detected_plates = []
        self.recent_plates = deque(maxlen=10)  # 5 -> 10 –±–æ–ª–≥–æ–≤
        
        # –ú–æ–Ω–≥–æ–ª –¥—É–≥–∞–∞—Ä—ã–Ω —Ñ–æ—Ä–º–∞—Ç—É—É–¥
        self.plate_patterns = [
            r'^[0-9]{4}[A-Z]{3}$',      # 1234ABC
            r'^[A-Z]{3}[0-9]{4}$',      # ABC1234
            r'^[0-9]{3}[A-Z]{2}[0-9]{2}$',  # 123AB12
            r'^[A-Z]{2}[0-9]{4}$',      # AB1234
            r'^[0-9]{2}[A-Z]{2}[0-9]{3}$',  # 12AB123
        ]
        
        print("‚úÖ –°–∏—Å—Ç–µ–º –±—ç–ª—ç–Ω!")
    
    def select_video(self):
        """–í–∏–¥–µ–æ —Ñ–∞–π–ª —Å–æ–Ω–≥–æ—Ö"""
        root = tk.Tk()
        root.withdraw()
        video_path = filedialog.askopenfilename(
            title="–í–∏–¥–µ–æ —Å–æ–Ω–≥–æ—Ö",
            filetypes=[
                ("Video files", "*.mp4 *.avi *.mov *.mkv"),
                ("All files", "*.*")
            ]
        )
        root.destroy()
        return video_path
    
    def is_duplicate(self, text):
        """–î–∞–≤—Ö—Ü—Å–∞–Ω —ç—Å—ç—Ö–∏–π–≥ —à–∞–ª–≥–∞—Ö"""
        if not text or len(text) < 4:
            return True
        # –¢”©—Å—Ç—ç–π –¥—É–≥–∞–∞—Ä —Ö–∞–π—Ö (1 —Ç—ç–º–¥—ç–≥—Ç –∑”©—Ä“Ø“Ø—Ç—ç–π —á)
        for plate in self.recent_plates:
            similarity = sum(a == b for a, b in zip(text, plate))
            if len(text) == len(plate) and similarity >= len(text) - 1:
                return True
        return False
    
    def is_valid_mongolian_plate(self, text):
        """–ú–æ–Ω–≥–æ–ª –¥—É–≥–∞–∞—Ä—ã–Ω —Ñ–æ—Ä–º–∞—Ç —ç—Å—ç—Ö–∏–π–≥ —à–∞–ª–≥–∞—Ö"""
        if not text or len(text) < 5 or len(text) > 8:
            return False
        
        for pattern in self.plate_patterns:
            if re.match(pattern, text):
                return True
        return False
    
    def detect_plates(self, frame):
        """–î—É–≥–∞–∞—Ä –∏–ª—Ä“Ø“Ø–ª—ç—Ö - –ò–õ“Æ“Æ –ù–ê–†–ò–ô–í–ß–õ–ê–õ–¢–ê–ô"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # Contrast —Å–∞–π–∂—Ä—É—É–ª–∞—Ö
        gray = cv2.equalizeHist(gray)
        
        # –®—É–º –∞—Ä–∏–ª–≥–∞—Ö
        gray = cv2.bilateralFilter(gray, 11, 17, 17)
        
        # –û–ª–æ–Ω scale-—ç—ç—Ä —Ö–∞–π—Ö
        all_plates = []
        for scale in [1.03, 1.05, 1.08, 1.1]:
            plates = self.cascade.detectMultiScale(
                gray, 
                scaleFactor=scale,
                minNeighbors=3,
                minSize=(80, 25),  # –ë–∞–≥–∞ –¥—É–≥–∞–∞—Ä
                maxSize=(400, 150)
            )
            if len(plates) > 0:
                all_plates.extend(plates)
        
        # –î–∞–≤—Ö—Ü—Å–∞–Ω —Ö“Ø—Ä—ç—ç–Ω“Ø“Ø–¥–∏–π–≥ –∞—Ä–∏–ª–≥–∞—Ö
        if len(all_plates) > 0:
            all_plates = self.remove_overlapping(all_plates)
        
        return all_plates
    
    def remove_overlapping(self, boxes):
        """–î–∞–≤—Ö—Ü—Å–∞–Ω –±–æ–∫—Å –∞—Ä–∏–ª–≥–∞—Ö"""
        if len(boxes) == 0:
            return []
        
        boxes = np.array(boxes)
        pick = []
        
        x1 = boxes[:, 0]
        y1 = boxes[:, 1]
        x2 = boxes[:, 0] + boxes[:, 2]
        y2 = boxes[:, 1] + boxes[:, 3]
        area = boxes[:, 2] * boxes[:, 3]
        
        idxs = np.argsort(area)[::-1]  # –¢–æ–º box —ç—Ö—ç–ª–∂
        
        while len(idxs) > 0:
            i = idxs[0]
            pick.append(i)
            
            # Overlap —à–∞–ª–≥–∞—Ö
            xx1 = np.maximum(x1[i], x1[idxs[1:]])
            yy1 = np.maximum(y1[i], y1[idxs[1:]])
            xx2 = np.minimum(x2[i], x2[idxs[1:]])
            yy2 = np.minimum(y2[i], y2[idxs[1:]])
            
            w = np.maximum(0, xx2 - xx1)
            h = np.maximum(0, yy2 - yy1)
            overlap = (w * h) / area[idxs[1:]]
            
            idxs = np.delete(idxs, np.concatenate(([0], np.where(overlap > 0.3)[0] + 1)))
        
        return boxes[pick]
    
    def preprocess_plate(self, plate_img):
        """–ó—É—Ä–∞–≥ –ú–ê–ê–®–ì“Æ–ô –°–ê–ô–ù –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö"""
        if len(plate_img.shape) == 3:
            gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)
        else:
            gray = plate_img.copy()
        
        # 1. –¢–û–ú –ë–û–õ–ì–û–• (300 pixel ”©–Ω–¥”©—Ä)
        h, w = gray.shape
        if h < 100:  # –•—ç—Ç –±–∞–≥–∞ –±–æ–ª
            scale = 300 / h
            new_w = int(w * scale)
            gray = cv2.resize(gray, (new_w, 300), interpolation=cv2.INTER_CUBIC)
        
        # 2. –®—É–º –∞—Ä–∏–ª–≥–∞—Ö - –•“Æ–ß–¢–≠–ô
        gray = cv2.fastNlMeansDenoising(gray, h=15)
        
        # 3. Contrast - CLAHE
        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8,8))
        gray = clahe.apply(gray)
        
        # 4. –ì—ç—Ä—ç–ª—Ç“Ø“Ø–ª—ç–≥ —Ç—ç–≥—à–ª—ç—Ö
        gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)
        
        # 5. Sharpening - –•“Æ–ß–¢–≠–ô
        kernel = np.array([[-1,-1,-1],
                          [-1, 10,-1],
                          [-1,-1,-1]])
        gray = cv2.filter2D(gray, -1, kernel)
        
        # 6. Morphology - —Ç–µ–∫—Å—Ç —Ç–æ–¥—Ä—É—É–ª–∞—Ö
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        gray = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)
        gray = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)
        
        # 7. OTSU threshold (adaptive-–∞–∞—Å –¥—ç—ç—Ä)
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # 8. –î–∞—Ö–∏–Ω —Ü—ç–≤—ç—Ä–ª—ç—Ö
        binary = cv2.medianBlur(binary, 3)
        
        # 9. Dilate - —Ç—ç–º–¥—ç–≥—Ç“Ø“Ø–¥ —Ö–æ–ª–±–æ—Ö
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))
        binary = cv2.dilate(binary, kernel, iterations=1)
        
        return binary
    
    def recognize_text(self, plate_img):
        """OCR - ”®–ù–î”®–† –ù–ê–†–ò–ô–í–ß–õ–ê–õ–¢–ê–ô"""
        try:
            processed = self.preprocess_plate(plate_img)
            
            # OCR —Ç–æ—Ö–∏—Ä–≥–æ–æ - –ú–æ–Ω–≥–æ–ª –¥—É–≥–∞–∞—Ä—Ç —Ç–æ—Ö–∏—Ä—É—É–ª—Å–∞–Ω
            configs = [
                '--oem 3 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',
                '--oem 3 --psm 8 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',
                '--oem 1 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',
                '--oem 3 --psm 13 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',
            ]
            
            results = []
            for config in configs:
                try:
                    # –≠—Ö –∑—É—Ä–∞–≥
                    text1 = pytesseract.image_to_string(processed, config=config)
                    cleaned1 = self.clean_text(text1)
                    if cleaned1 and self.is_valid_mongolian_plate(cleaned1):
                        results.append(cleaned1)
                    
                    # –£—Ä–≤—É—É –∑—É—Ä–∞–≥
                    inverted = cv2.bitwise_not(processed)
                    text2 = pytesseract.image_to_string(inverted, config=config)
                    cleaned2 = self.clean_text(text2)
                    if cleaned2 and self.is_valid_mongolian_plate(cleaned2):
                        results.append(cleaned2)
                except:
                    pass
            
            if results:
                from collections import Counter
                counter = Counter(results)
                best_text, count = counter.most_common(1)[0]
                confidence = (count / len(results)) * 100 if results else 0
                
                # –ó”©–≤—Ö”©–Ω ”©–Ω–¥”©—Ä –∏—Ç–≥—ç–ª—Ç—Ç—ç–π “Ø—Ä –¥“Ø–Ω –±—É—Ü–∞–∞—Ö
                if confidence >= 30:  # 30%-–∞–∞—Å –¥—ç—ç—à
                    return best_text, confidence
        except Exception as e:
            pass
        
        return None, 0
    
    def clean_text(self, text):
        """–¢–µ–∫—Å—Ç —Ü—ç–≤—ç—Ä–ª—ç—Ö + –ó–ê–°–ê–•"""
        cleaned = ''.join(c for c in text if c.isalnum())
        cleaned = cleaned.upper().strip()
        
        # –ê–ª–¥–∞–∞—Ç–∞–π —Ç—ç–º–¥—ç–≥—Ç –∑–∞—Å–∞—Ö
        replacements = {
            'O': '0', 'I': '1', 'Z': '2', 'S': '5', 
            'B': '8', 'G': '6', 'Q': '0', 'D': '0',
            '0': 'O', '1': 'I', '5': 'S', '8': 'B',  # –≠—Å—Ä—ç–≥ —á–∏–≥–ª—ç–ª
        }
        
        # –¢–æ–æ –±–∞ “Ø—Å–≥–∏–π–Ω –±–∞–π—Ä—à–∏–ª —Ö–∞—Ä–≥–∞–ª–∑–∞–Ω –∑–∞—Å–∞—Ö
        result = []
        for i, char in enumerate(cleaned):
            # –≠—Ö–Ω–∏–π 2-4 —Ç—ç–º–¥—ç–≥—Ç —Ç–æ–æ –±–∞–π—Ö —ë—Å—Ç–æ–π (–∏—Ö—ç–Ω—Ö —Ç–æ—Ö–∏–æ–ª–¥–æ–ª–¥)
            if i < 3 and char.isalpha() and char in replacements.values():
                # “Æ—Å–≥–∏–π–≥ —Ç–æ–æ –±–æ–ª–≥–æ—Ö
                for k, v in replacements.items():
                    if v == char and k.isdigit():
                        char = k
                        break
            # –°“Ø“Ø–ª–∏–π–Ω 2-3 —Ç—ç–º–¥—ç–≥—Ç “Ø—Å—ç–≥ –±–∞–π—Ö —ë—Å—Ç–æ–π
            elif i >= len(cleaned) - 3 and char.isdigit() and char in replacements:
                char = replacements[char]
            
            result.append(char)
        
        cleaned = ''.join(result)
        
        if len(cleaned) < 5 or len(cleaned) > 8:
            return None
        
        return cleaned
    
    def draw_table(self, frame):
        """–•“Ø—Å–Ω—ç–≥—Ç –∑—É—Ä–∞—Ö"""
        h, w = frame.shape[:2]
        table_width = 350
        table_x = w - table_width
        
        overlay = frame.copy()
        cv2.rectangle(overlay, (table_x, 0), (w, h), (20, 20, 20), -1)
        cv2.addWeighted(overlay, 0.85, frame, 0.15, 0, frame)
        
        cv2.rectangle(frame, (table_x, 0), (w, 50), (0, 100, 200), -1)
        cv2.putText(frame, "TANISAN DUGAARUD", 
                   (table_x + 10, 32), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255, 255, 255), 2)
        
        y = 60
        cv2.line(frame, (table_x, y), (w, y), (100, 100, 100), 2)
        cv2.putText(frame, "Tsag", (table_x + 10, y + 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
        cv2.putText(frame, "Dugaar", (table_x + 100, y + 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
        cv2.putText(frame, "%", (table_x + 280, y + 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
        
        y += 35
        cv2.line(frame, (table_x, y), (w, y), (100, 100, 100), 1)
        
        start_idx = max(0, len(self.detected_plates) - 12)
        for i, detection in enumerate(self.detected_plates[start_idx:]):
            y += 40
            if y > h - 20:
                break
            
            time_str = detection['time'].strftime("%H:%M:%S")
            plate = detection['plate']
            conf = detection['confidence']
            
            cv2.putText(frame, time_str, (table_x + 10, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
            
            color = (0, 255, 0) if conf > 70 else (0, 200, 255) if conf > 40 else (0, 100, 255)
            cv2.putText(frame, plate, (table_x + 100, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)
            
            cv2.putText(frame, f"{conf:.0f}", (table_x + 280, y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        cv2.rectangle(frame, (table_x, h - 60), (w, h), (40, 40, 40), -1)
        cv2.putText(frame, f"Niit: {len(self.detected_plates)}", 
                   (table_x + 10, h - 35), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 100), 1)
        
        high_conf = sum(1 for d in self.detected_plates if d['confidence'] > 70)
        cv2.putText(frame, f"Ondor: {high_conf}", 
                   (table_x + 10, h - 12), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 100), 1)
        
        return frame
    
    def draw_detection(self, frame, x, y, w, h, text, confidence):
        """–î—É–≥–∞–∞—Ä –¥—ç—ç—Ä —Ö“Ø—Ä—ç—ç"""
        if confidence > 70:
            color = (0, 255, 0)
        elif confidence > 40:
            color = (0, 200, 255)
        else:
            color = (0, 100, 255)
        
        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
        
        if text:
            label = f"{text} ({confidence:.0f}%)"
            text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
            
            cv2.rectangle(frame, (x, y-30), (x + text_size[0] + 10, y), (0, 0, 0), -1)
            cv2.rectangle(frame, (x, y-30), (x + text_size[0] + 10, y), color, 2)
            
            cv2.putText(frame, label, (x + 5, y - 8), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        return frame
    
    def save_to_file(self):
        """Excel —Ñ–∞–π–ª “Ø“Ø—Å–≥—ç—Ö"""
        if not self.detected_plates:
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        txt_file = os.path.join(self.save_folder, f"report_{timestamp}.txt")
        
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write("="*60 + "\n")
            f.write("–ú–ê–®–ò–ù–´ –î–£–ì–ê–ê–† –¢–ê–ù–ò–• - –¢–ê–ô–õ–ê–ù\n")
            f.write("="*60 + "\n\n")
            f.write(f"–û–≥–Ω–æ–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"–ù–∏–π—Ç —Ç–∞–Ω–∏–≥–¥—Å–∞–Ω: {len(self.detected_plates)}\n\n")
            f.write("-"*60 + "\n")
            f.write(f"{'‚Ññ':<5} {'–¶–∞–≥':<12} {'–î—É–≥–∞–∞—Ä':<15} {'–ò—Ç–≥—ç–ª—Ç':<10}\n")
            f.write("-"*60 + "\n")
            
            for i, det in enumerate(self.detected_plates, 1):
                time_str = det['time'].strftime("%H:%M:%S")
                f.write(f"{i:<5} {time_str:<12} {det['plate']:<15} {det['confidence']:.1f}%\n")
        
        print(f"\nüíæ –¢–∞–π–ª–∞–Ω —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞: {txt_file}")

def main():
    print("\n" + "="*70)
    print(" "*10 + "üöó –°–ê–ô–ñ–†–£–£–õ–°–ê–ù –í–ò–î–ï–û –î–£–ì–ê–ê–† –¢–ê–ù–ò–• üöó")
    print("="*70)
    print("\nüìå –®–∏–Ω—ç –æ–Ω—Ü–ª–æ–≥:")
    print("  ‚úì –î–∞–≤—Ö—Ü—Å–∞–Ω box –∞—Ä–∏–ª–≥–∞—Ö")
    print("  ‚úì –ú–æ–Ω–≥–æ–ª –¥—É–≥–∞–∞—Ä—ã–Ω —Ñ–æ—Ä–º–∞—Ç —à–∞–ª–≥–∞—Ö")
    print("  ‚úì –ê–ª–¥–∞–∞—Ç–∞–π —Ç—ç–º–¥—ç–≥—Ç –∑–∞—Å–∞—Ö (O‚Üí0, I‚Üí1)")
    print("  ‚úì –ó—É—Ä–∞–≥ –∏–ª“Ø“Ø —Ç–æ–º –±–æ–ª–≥–æ—Ö (300px)")
    print("  ‚úì –û–ª–æ–Ω scale-—ç—ç—Ä —Ö–∞–π—Ö")
    print("  ‚úì Confidence —à–∞–ª–≥—É—É—Ä —Ö–∞—Ç—É—É –±–æ–ª–≥–æ—Å–æ–Ω")
    print("\n" + "-"*70 + "\n")
    
    detector = VideoPlateDetector()
    
    print("üìÅ –í–∏–¥–µ–æ —Ñ–∞–π–ª —Å–æ–Ω–≥–æ—Ö —Ü–æ–Ω—Ö –Ω—ç—ç–≥–¥—ç–Ω—ç...")
    video_path = detector.select_video()
    
    if not video_path:
        print("‚ùå –í–∏–¥–µ–æ —Å–æ–Ω–≥–æ–≥–¥—Å–æ–Ω–≥“Ø–π!")
        return
    
    print(f"‚úÖ –í–∏–¥–µ–æ: {os.path.basename(video_path)}\n")
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("‚ùå –í–∏–¥–µ–æ –Ω—ç—ç–≥–¥—Å—ç–Ω–≥“Ø–π!")
        return
    
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"üé¨ FPS: {fps} | –ù–∏–π—Ç frame: {total_frames}")
    print(f"‚è±Ô∏è  “Æ—Ä–≥—ç–ª–∂–ª—ç—Ö —Ö—É–≥–∞—Ü–∞–∞: {total_frames/fps:.1f} —Å–µ–∫—É–Ω–¥\n")
    print("üöÄ –¢–∞–Ω–∏—Ö —ç—Ö—ç–ª–ª—ç—ç...\n")
    print("   SPACE - –¢“Ø—Ä –∑–æ–≥—Å–æ–æ—Ö/“Æ—Ä–≥—ç–ª–∂–ª“Ø“Ø–ª—ç—Ö")
    print("   Q - –î—É—É—Å–≥–∞—Ö\n")
    print("-"*70 + "\n")
    
    frame_count = 0
    paused = False
    
    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                print("\n‚úÖ –í–∏–¥–µ–æ –¥—É—É—Å–ª–∞–∞!")
                break
            
            frame_count += 1
            
            # Resolution - –ë–ê–ì–ê –ë–ê–ì–ê–°–ì–ê–• (1920px —Ö“Ø—Ä—Ç—ç–ª)
            h, w = frame.shape[:2]
            if w > 1920:
                scale = 1920 / w
                frame = cv2.resize(frame, (1920, int(h * scale)))
            
            # 3 frame —Ç—É—Ç–∞–º–¥ —Ç–∞–Ω–∏—Ö (5‚Üí3 –±–æ–ª–≥–æ–≤)
            if frame_count % 3 == 0:
                plates = detector.detect_plates(frame)
                
                for (x, y, w_p, h_p) in plates:
                    # –ó—É—Ä–∞–≥ –æ–≥—Ç–æ–ª–æ—Ö “Ø–µ–¥ margin –Ω—ç–º—ç—Ö
                    margin = 5
                    y1 = max(0, y - margin)
                    y2 = min(frame.shape[0], y + h_p + margin)
                    x1 = max(0, x - margin)
                    x2 = min(frame.shape[1], x + w_p + margin)
                    
                    plate_img = frame[y1:y2, x1:x2]
                    
                    if plate_img.size == 0:
                        continue
                    
                    text, confidence = detector.recognize_text(plate_img)
                    
                    if text and not detector.is_duplicate(text):
                        detector.detected_plates.append({
                            'time': datetime.now(),
                            'plate': text,
                            'confidence': confidence,
                            'image': plate_img.copy()
                        })
                        detector.recent_plates.append(text)
                        
                        print(f"‚úÖ –®–∏–Ω—ç: {text} ({confidence:.0f}%) | –ù–∏–π—Ç: {len(detector.detected_plates)}")
                    
                    if text:
                        frame = detector.draw_detection(frame, x, y, w_p, h_p, text, confidence)
            
            frame = detector.draw_table(frame)
            
            progress = (frame_count / total_frames) * 100
            cv2.putText(frame, f"Progress: {progress:.1f}%", 
                       (10, frame.shape[0] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (100, 200, 100), 2)
        
        cv2.imshow('Video Dugaar Tanikh', frame)
        
        key = cv2.waitKey(1 if not paused else 0) & 0xFF
        if key == ord('q') or key == ord('Q'):
            break
        elif key == ord(' '):
            paused = not paused
            print("‚è∏Ô∏è  –ó–æ–≥—Å–æ–æ—Å–æ–Ω" if paused else "‚ñ∂Ô∏è  “Æ—Ä–≥—ç–ª–∂–∏–ª–∂ –±–∞–π–Ω–∞")
    
    cap.release()
    cv2.destroyAllWindows()
    
    if detector.detected_plates:
        detector.save_to_file()
    
    print("\n" + "="*70)
    print(" "*25 + "üìä –î“Æ–ì–ù–≠–õ–¢")
    print("="*70)
    print(f"–ù–∏–π—Ç —Ç–∞–Ω–∏–≥–¥—Å–∞–Ω: {len(detector.detected_plates)}")
    
    high_conf = sum(1 for d in detector.detected_plates if d['confidence'] > 70)
    med_conf = sum(1 for d in detector.detected_plates if 40 <= d['confidence'] <= 70)
    low_conf = sum(1 for d in detector.detected_plates if d['confidence'] < 40)
    
    print(f"”®–Ω–¥”©—Ä –∏—Ç–≥—ç–ª—Ç—Ç—ç–π (>70%): {high_conf}")
    print(f"–î—É–Ω–¥ –∏—Ç–≥—ç–ª—Ç—Ç—ç–π (40-70%): {med_conf}")
    print(f"–ë–∞–≥–∞ –∏—Ç–≥—ç–ª—Ç—Ç—ç–π (<40%): {low_conf}")
    
    print(f"\nüíæ –§–∞–π–ª—É—É–¥: {detector.save_folder}/")
    print("\nüëã –ë–∞—è—Ä—Ç–∞–π!")
    print("="*70 + "\n")

if __name__ == "__main__":
    main()